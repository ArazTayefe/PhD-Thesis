\chapter{Introduction}

\ac{fl} is a groundbreaking approach to machine learning that allows models to be trained directly on edge devices without centralizing data. This method addresses significant concerns regarding data privacy and security by keeping sensitive information local to the device it originates from, thus preventing data leakage and enhancing user privacy. \ac{fl} represents a shift towards decentralized, privacy-preserving machine learning models, making it a critical area of research for advancing machine learning technologies that are both accessible and secure.

\begin{figure}[H]
    \centering 
    \includegraphics{Figures/Schematic of Federated Learning.pdf}
    \caption{Schematic diagram to illustrate distributed learning and \ac{fl} \cite{Ch_1_R1}.}
    \label{Sch_FL}
\end{figure}

Figure \ref{Sch_FL} shows a diagram of distributed learning and \ac{fl}. In conventional learning, the data is collected from the clients, and the model is trained offline. In distributed learning, the dataset is collected at a single data store, and then it is distributed across multiple worker nodes for training. In \ac{fl}, the training is performed at the client, and model gradients are communicated to the central server, which aggregates the gradients, updates the global model, and broadcasts it back to all the clients. Each of these processes is iterative, and models for the clients are periodically updated.

\ac{snn}s bring a new dimension to the capabilities of \ac{fl}. Inspired by the biological processes of the human brain, \ac{snn}s operate on an event-driven basis, processing information only in response to stimuli. This method of operation significantly reduces the power consumption of these networks, making them particularly suited for deployment across distributed, battery-operated devices. The integration of \ac{snn}s with \ac{fl} leverages these unique advantages, combining energy efficiency with the privacy-preserving features of \ac{fl} to address the challenges faced by traditional artificial neural network models in federated settings \cite{Ch_1_R2, Ch_1_R3}.

The energy-efficient nature of \ac{snn}s aligns perfectly with the objectives of \ac{fl}, where models are trained across a network of distributed devices without centralized data collection. Unlike conventional artificial neural networks that require continuous data flow and computation, \ac{snn}s' event-driven operation allows for significant reductions in energy consumption, which is critical for battery-operated agents participating in \ac{fl}. This characteristic of \ac{snn}s supports the development of low-power, distributed learning solutions, enabling more agents to participate in \ac{fl} without compromising on power efficiency \cite{Ch_1_R4}.

Furthermore, the integration of \ac{snn}s in \ac{fl} scenarios can also help overcome limitations associated with bandwidth-constrained environments. The sparse nature of data representation and communication in \ac{snn}s means that less information needs to be exchanged between devices and the central server during the training process. This efficiency is crucial in \ac{fl} environments, where network bandwidth and connectivity can significantly impact the feasibility and performance of distributed learning systems \cite{Ch_1_R5}.

Another critical advantage of \ac{snn}s in the context of \ac{fl} is their compatibility with neuromorphic hardware. Neuromorphic chips, designed to replicate the neural structures of the human brain, provide an ideal platform for deploying \ac{snn}s. This synergy between neuromorphic computing and \ac{snn}s paves the way for the development of highly efficient, scalable, and adaptive \ac{fl} systems capable of leveraging the full potential of edge computing \cite{Ch_1_R6}.

Despite these advantages, the integration of \ac{snn}s with \ac{fl} presents several challenges. The primary hurdle is the complexity of training \ac{snn}s in complex problems. The dynamic and temporal nature of \ac{snn}s introduces new challenges in developing effective \ac{fl} protocols that can accommodate the unique online learning rules of \ac{snn}s. Proper scheduling of communication rounds within the local \ac{snn} time steps is essential for successful collaborative training \cite{Ch_1_R7}.

Moreover, managing the performance trade-offs associated with the frequency of communication rounds in \ac{fl} is another significant challenge. Experiments have shown the impact of the number of time steps between local updates and the frequency of model aggregation on the training performance of \ac{snn}s. Finding an optimal balance to maximize model performance while minimizing communication overhead is crucial for the efficient deployment of \ac{fl} systems powered by \ac{snn}s \cite{Ch_1_R8}.

Additionally, communication constraints and the non-stationarity of data distribution pose significant challenges. The need for larger model update intervals to reduce communication costs and the changing nature of data over time (e.g., reward function in RL) require innovative solutions to maintain the accuracy and reliability of \ac{fl} systems employing \ac{snn}s \cite{Ch_1_R9}.

Despite these challenges, the potential benefits of integrating \ac{snn}s with \ac{fl} justify continued research and development in this area. The combination of energy efficiency, privacy preservation, and compatibility with neuromorphic hardware, along with the distributed and collaborative nature of \ac{fl}, represents a compelling approach to deploying machine learning models in real-world applications \cite{Ch_1_R10}.


\section{Spiking Neural Networks: Models and Learning Algorithms}

\subsection{Neuron model}

In the study of computational neuroscience and the development of neural networks, particularly \ac{snn}, various neuron models have been proposed to simulate the electrical activity of neurons. These models range from simple to complex, aiming to capture the essential features of neuronal dynamics. The diagram in Figure \ref{Fig.SimplMdlSNN} illustrates a basic network consisting of spiking neurons. In this network, the pre-synaptic neuron (pre-neuron) in the input layer spikes in response to the input (I) and transmits these spikes through synaptic weights to the post-synaptic neuron (post-neuron). Whenever the pre-neuron spikes, the post-neuron receives input current with a value of W.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Figures/Simple Spiking Neural Network.pdf}
    \caption{Simple model of a \ac{snn}. The spike pattern shows that the neurons spike whenever the voltage of the neuron reaches a threshold.}
    \label{Fig.SimplMdlSNN}
\end{figure}

Table \ref{Table.SRF} shows the differential equations used in the network. In \ac{snn}s, the activation function, like ReLu and tanh in regular neural networks, is replaced by a differential equation that mimics the biological neuron activity.

\begin{table}[H]
    \centering
    \begin{tabular}{cc}
        \toprule
        & \textbf{Spike Response Function} \\
        \midrule
        \textbf{Pre-Neuron} & $\dot{V}_1 = \frac{1}{\tau_m} \left[ E_L - V_1 + R_m I \right]$ \\
        \midrule
        \textbf{Post-Neuron} & $\dot{V}_2 = \frac{1}{\tau_m} \left[ E_L - V_2 + R_m \left( W \delta (t - t_{\text{pre}}) \right) \right]$ \\
        \bottomrule
    \end{tabular}
    \caption{Spike Response Function of the neurons in an \ac{snn}.}
    \label{Table.SRF}
\end{table}

Several spike response functions have been proposed to emulate neuron activity. In this chapter, the Leaky-Integrate and Fire model is represented because it is simple and accurate enough in emulating real neurons. This section overviews the neuron model and its characteristics.


\subsubsection{Leaky-Integrate and Fire model}
The \ac{lif} model is a biological model that can be represented as a circuit with a resistor and capacitor and represents a first-order dynamic system \cite{Ch_1_R13},

\begin{equation} \label{Eq.1}
    R_{m}C_{m}\frac{dV_m\left(t\right)}{dt} = E_{l} - V_m\left(t\right) + R_{m}I\left(t\right)
\end{equation}

\noindent where $V_{m}(t)$ is the neuron's membrane potential shown as \(V_{1}\) and \(V_{2}\) in Table \ref{Table.SRF}, $R_{m}$ is the membrane resistance, $C_{m}$ is the membrane capacitance, $E_{l}$ is the resting potential, and $I(t)$ is the input current. The neuron spikes when its potential reaches the threshold potential ($V_{th}$). The potential of the neuron immediately reaches the reset potential ($V_{res}$) after it spikes.

The spike rate is a parameter that determines how fast the neuron spikes \cite{Ch_1_R11}.

\begin{equation} \label{Eq.4}
    r_{[Hz]} = \frac{1}{t_{isi}\enspace [s]}
\end{equation}

\noindent where $t_{isi}$ is the inter-spike interval that can be calculated using the neuron model, when the potential of a neuron reaches the threshold potential, it fires. Therefore, based on the analytical solution of (\ref{Eq.1}), the inter-spike interval time can be written as,

\begin{equation} \label{Eq.7}
    t_{isi} = \tau_{m}\ln\left(\frac{E_{l} + R_{m}I - V_{res}}{E_{l} + R_{m}I - V_{th}}\right)
\end{equation}

\noindent where $\tau_{m}$ is the membrane time constant. 

According to (\ref{Eq.7}), the following condition should be satisfied to have a finite value for $t_{isi}$,

\begin{equation} \label{Eq.8}
    E_{l} + R_{m}I - V_{th} > 0
\end{equation}

\noindent or

\begin{equation} \label{Eq.9}
    I > \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

\noindent which means that the input current higher than the above value generates spikes. 

After calculating the minimum input for neurons, we must find the maximum input based on the inter-spike interval. Equation (\ref{Eq.7}) can be written as,

\begin{equation} \label{Eq.10}
    t_{isi} = \tau_{m}\ln\left(1+\frac{V_{th} - V_{res}}{E_{l} + R_{m}I - V_{th}}\right)
\end{equation}

\noindent Equation (\ref{Eq.10}) can be approximated using the Maclaurin series for the natural logarithm function ($\ln(1+z)\approx z$) as follows,

\begin{equation} \label{Eq.11}
    t_{isi} = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{E_{l} + R_{m}I - V_{th}}
\end{equation}

\noindent Solving for $I$, an input current as a function of the inter-spike interval can be obtained,

\begin{equation} \label{Eq.12}
    I = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{t_{isi}R_{m}} + \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

The maximum value for the input current makes the neuron fire at each sample time ($\Delta t$). Therefore, the maximum input current is,

\begin{equation} \label{Eq.13}
    I^{max} = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{\Delta t R_{m}} + \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

In this section, we obtained the minimum and maximum values for input current using (\ref{Eq.9}) and (\ref{Eq.13}). These equations are used in the learning and encoding processes of the \ac{snn}.


\subsection{Learning Approaches in SNNs}

\subsection*{Hebbian Learning}


Hebbian Learning is a fundamental neural learning principle summarized by the axiom ``neurons that fire together, wire together," describing how simultaneous activation of neurons leads to strengthened connections between them~\cite{Ch_1_R16}. Hebbian learning, particularly within the context of \ac{snn}, primarily revolves around the modulation of synaptic strengths based on the firing rates of pre- and postsynaptic neurons. The principles of locality and joint activity are fundamental, emphasizing that synaptic changes occur only when both neurons are active simultaneously.

\textbf{Methods of Synaptic Modification:}
\begin{itemize}
    \item \textbf{Local Rules:} Synaptic changes are influenced directly by the activities of the connecting neurons without external influences.
    \item \textbf{Bounded Growth:} To avoid uncontrolled increases in synaptic strength, models typically incorporate mechanisms such as hard and soft bounds. Hard bounds prevent any further increase once a maximum weight is achieved, while soft bounds slow down the rate of increase as the maximum is approached~\cite{Ch_1_R25}.
    \item \textbf{Synaptic Decay:} Realistic models also consider mechanisms for reducing synaptic strengths, typically through a decay term that weakens connections in the absence of activity~\cite{Ch_1_R17}.
\end{itemize}

\textbf{Advanced Hebbian Models:}
\begin{itemize}
    \item \textbf{Covariance Rule:} This model refines the synaptic modification to depend on the deviation of firing rates from their means, enhancing the dynamic response of synapses to changes in neural activity~\cite{Ch_1_R32}.
    \item \textbf{Oja's Rule:} A self-stabilizing rule that ensures synaptic weights do not grow indefinitely by normalizing the weight vector, thereby maintaining the overall stability of the network~\cite{Ch_1_R19}.
    \item \textbf{BCM Rule:} The Bienenstock-Cooper-Munro rule introduces an adaptive threshold for synaptic modification, which evolves based on the historical activity of the neuron, allowing for more refined potentiation and depression based on relative activity levels.~\cite{Ch_1_R31}.
    \item \textbf{RCHP:} Rarely Correlating Hebbian Plasticity focuses on synaptic changes driven by rare, significant coincidences in neuronal activity, aiming to strengthen connections that are crucial for neural function while avoiding over-strengthening due to common activity patterns~\cite{Ch_1_R20}.
\end{itemize}

\textbf{Incorporation into Reinforcement Learning:}
Modern adaptations in \ac{snn}s integrate the concept of rewards, adding a third dimension to synaptic adjustments. This integration uses scaling or gating mechanisms in response to global reward signals, further refining the learning capabilities of neural networks based on external feedback.


\subsection*{Neo-Hebbian Learning and Modulation Mechanisms}

In neo-Hebbian reinforcement learning, significant advancements come from a global reward signal modulating synaptic plasticity alongside an eligibility trace that decays over time~\cite{Ch_1_R21}. This trace increases with recent, successful neurotransmission and decreases as time passes, linking closely with Temporal-Difference (TD) learning mechanisms. Such dynamics allow for Long-Term Potentiation (LTP) or Depression (LTD) at synapses based on the timing of synaptic activity and the nature of the reward signal. Specifically, recent successful activities followed by positive rewards enhance LTP, while activities preceding negative rewards lead to LTD.



\textbf{Distal rewards and credit assignment} 

This model introduces a sophisticated approach to synaptic modification through the interaction of \ac{stdp} with a modulatory signal reflective of reward, embodying the essence of TD learning within the realm of spiking neurons.

Central to this framework is the eligibility trace mechanism, elegantly adapted from its conventional application in TD learning to facilitate synaptic credit assignment over varying temporal extents. This adaptation allows for the dynamic modulation of synaptic strengths based on the timing and sequence of pre- and post-synaptic spikes, in conjunction with the temporal dynamics of received rewards. The eligibility trace is mathematically represented as follows~\cite{Ch_1_R22}:

\begin{equation}
    \frac{dC_{ji}}{dt} = -\frac{C_{ji}}{\tau_{C}} + \text{STDP}(t_{\text{post}} - t_{\text{pre}})\delta(t - t^{(f)})
\end{equation}

Here, $C_{ji}(t)$ denotes the eligibility trace for the synapse between pre-synaptic neuron $j$ and post-synaptic neuron $i$, evolving with a decay governed by $\tau_{C}$. The Dirac delta function, $\delta(t - t^{(f)})$, signifies the occurrence of a spike, serving as a pivotal factor in the temporal credit assignment process. 

The STDP function can be represented as follows,

\begin{equation}
    STDP(\tau) = \mathcal{A} \exp\left(-\frac{\tau}{\tau_{s}}\right) \text{for \(\tau \geq 0\)}, (\tau = t_{\text{post}} - t_{\text{pre}})
\end{equation}

\noindent where \(\mathcal{A}\) stands as the amplitude and \(\tau_{s}\) acts as the time constant.

Synaptic weight updates are then guided by the interaction between the eligibility trace and the reward signal, $R(t)$, as captured in the following equation:

\begin{equation}
    \frac{dw_{ji}}{dt} = C_{ji}(t) \cdot R(t)
\end{equation}

\noindent where $dw_{ji}/dt$ symbolizes the rate of change in synaptic weight, contingent upon the compounded influence of the eligibility trace and the reward signal.


\section{Literature Review}

\subsection{Spiking Neural Network}

\ac{snn}s have garnered significant attention for their ability to emulate complex neural dynamics observed in biological systems. This literature review focuses on the learning mechanisms, including STDP, and their implications in modeling biological learning behaviors.

Besides the LIF model, there are different types of \ac{snn} models. The Hodgkin-Huxley model is a foundational framework in neuroscience that meticulously describes the ionic processes critical for the initiation and propagation of action potentials in neurons~\cite{Ch_1_R12}. The model uses differential equations to capture the dynamics of membrane potential (\(V\)) influenced by various ion-specific currents and gating variables, which regulate ion channel states. These gating variables, which transition between 0 and 1, reflect the proportion of ion channels in different states, crucial for mimicking the action potentials’ temporal complexity. In contrast, the FitzHugh-Nagumo model simplifies the complex Hodgkin-Huxley framework into a two-variable system, focusing on capturing the essential characteristics of neuronal excitability with fewer computational demands.

The Izhikevich model merges the biological realism of the Hodgkin-Huxley model with the computational simplicity of integrate-and-fire models, offering a balanced approach for simulating neuronal behavior~\cite{izhikevich2003simple }. This model is particularly noted for its ability to produce diverse firing patterns with computational efficiency, making it suitable for simulating large networks of neurons while still capturing key aspects of neuronal activity.

The learning in \ac{snn}s is based on the timing between neurons firing. The STPD process is one of the biological processes observed in real neurons. The investigation of competitive Hebbian learning through STDP reveals how the timing of spikes modulates synaptic efficacy, underscoring the significance of temporal dynamics in synaptic modification within neural circuits \cite{Ch2_R9}. This highlights the critical role of spike timing in learning processes, which is essential for understanding neural adaptation.

In a significant study, the distal reward problem was tackled by linking STDP with dopamine signaling, illustrating a novel approach to reward-based learning in the brain \cite{Ch_1_R22}. This study proposed a model where dopamine modulates STDP mechanisms, effectively capturing the essence of reward-based learning processes.

Another research posited that STDP emerges from fundamental learning rules governed by intracellular calcium dynamics, suggesting a deeper biophysical basis for synaptic strength regulation \cite{Ch2_R6}. This challenges the traditional understanding of STDP and points towards a more comprehensive framework for neural plasticity.

An extensive review of the development and implications of STDP in neural circuits provided insights into its critical role in precise spike timing for synaptic modification, enriching our understanding of the neural basis for learning and memory \cite{Ch2_R5}. 

A study on multiagent reinforcement learning within the Iterated Prisoner's Dilemma framework highlighted \ac{snn}s' comparable or enhanced performance against traditional models \cite{Ch2_R4}. This emphasizes the critical role of spike timing in complex decision-making processes, showcasing \ac{snn}s' potential in simulating interactive and competitive environments.

The introduction of a model for parallel path planning using spiking neural activity, inspired by hippocampal navigation strategies, showcased the efficiency of \ac{snn}s in solving spatial navigation problems through biologically plausible mechanisms \cite{Ch2_R3}.

In a pioneering study, the implementation of probabilistic inference within networks of LIF neurons demonstrated how Bayesian networks can be transformed into a computable framework for \ac{snn}s \cite{Ch2_R1}. This methodology underscores \ac{snn}s' capability to perform complex cognitive functions through probabilistic reasoning.

The performance comparison between \ac{snn}s and multilayer perceptrons in a computer-based racing game highlighted \ac{snn}s' superior adaptability and decision-making capabilities in dynamic environments, attributed to the efficient processing of real-time data through spike-based mechanisms \cite{Ch2_R2}.

Hierarchical Bayesian inference within \ac{snn}s introduces a learning algorithm based on synaptic plasticity, showcasing the ability of \ac{snn}s to execute complex tasks like pattern recognition through hierarchical structures \cite{Ch2_R14}. This emphasizes the adaptability and computational efficiency of \ac{snn}s.

BP-STDP, which approximates backpropagation using STDP, bridges the gap between \ac{snn} mechanisms and traditional neural network computational efficiency \cite{Ch2_R16}. This algorithm advances learning algorithms for \ac{snn}s, making them more accessible for machine learning tasks.

Indirect and direct training methods for \ac{snn}s in end-to-end control of a lane-keeping vehicle highlight the effectiveness of both approaches in utilizing \ac{snn}s for real-world control tasks, providing insights into training \ac{snn}s for complex systems like autonomous vehicles \cite{Ch2_R17}.

N3-CPL, a neuroplasticity-based learning method for neuromorphic networks, focuses on cell proliferation in \ac{snn}s, enhancing learning capabilities through mechanisms inspired by biological neural network growth and adaptation \cite{Ch2_R18}.

Parameter optimization in an \ac{snn} model for UAV obstacle avoidance tackles the challenge of tuning \ac{snn} parameters for specific tasks using optimization techniques, emphasizing the importance of optimization in \ac{snn} application for real-time processing and decision-making \cite{Salt2019Parameter}.

A methodology for multi-task autonomous learning in mobile robots using \ac{snn}s was proposed, employing Modified Integrate-and-Fire and \ac{lif} neuron models, alongside a task switch mechanism inspired by lateral inhibition and a novel learning rule based on \ac{stdp}. This approach demonstrated \ac{snn}s' capabilities in efficiently learning and adapting across various tasks such as obstacle avoidance and target tracking \cite{Ch2_R20}.

An autonomous learning framework that combines \ac{snn}s with a pre-trained binary Convolutional Neural Network for image-based reinforcement learning was developed. This hybrid model efficiently processes high-dimensional sensory data and learns from sparse rewards, highlighting the synergistic potential of \ac{snn}s and CNNs in complex visual environments \cite{Ch2_R21}.

A transfer learning algorithm for \ac{snn}s aimed at deep learning tasks was introduced, utilizing Centered Kernel Alignment for domain distance measurement and focusing on domain-invariant representation. This methodology enables effective knowledge transfer, showcasing the scalability and adaptability of \ac{snn}s \cite{Ch2_R22}.

Mathematical constraints influencing Hebbian learning and STDP in \ac{snn}s were explored, revealing relationships between synaptic weight promotion/demotion probabilities and normalized weights, offering insights into optimizing \ac{snn} training \cite{Ch2_R24}.

``Spikepropamine," incorporating differentiable plasticity within \ac{snn}s, was presented. This approach enables adaptive learning and improved task performance, signifying advancements in neuromorphic computing and robotics applications of \ac{snn}s \cite{Ch2_R25}.

NeuronGPU, a library for simulating large-scale networks of spiking neurons with GPU acceleration, was developed. This tool demonstrated scalability and efficiency in simulating complex neuronal dynamics, marking a significant contribution to computational neuroscience tools \cite{Ch2_R26}.


\subsection{Federated Learning}


\ac{fl} aggregation methods form a cornerstone of how distributed models learn collectively while maintaining the privacy of local data. The seminal aggregation method in FL is FedAvg, or Federated Averaging. As introduced by McMahan et al.~\cite{Ch_1_R26}, FedAvg operates by averaging the weights of models updated locally by clients. This simple yet effective approach allows a global model to benefit from diverse local updates without sharing the data itself.

Addressing heterogeneity in client data distributions, the FedProx method~\cite{Ch_1_R27}, introduced by Li et al., modifies the local optimization process. FedProx introduces a proximal term which moderates the deviation of local updates from the global model, aiming to stabilize training across clients with non-IID data.

The Scaffold method~\cite{Ch_1_R28} deals with statistical heterogeneity and client drift, issues prevalent in scenarios where client data is not Independent and Identically Distributed (IID). Karimireddy et al. propose using control variates that correct the local updates toward the global objective, which helps in reducing variance in updates and aligning clients closer to the global model.

Introduced by Wang et al., the FedNova method~\cite{Ch_1_R29} employs a novel normalization mechanism in the aggregation process that adjusts based on the number of local updates performed by each client. This design accommodates the diversity in client update contributions, particularly beneficial in non-IID data scenarios.

The MOON method, or Model-contrastive Federated Learning, minimizes the contrastive loss between local and global models to maintain consistency across updates~\cite{Ch_1_R30}. By focusing on minimizing differences in model parameters using a similarity metric, MOON seeks to preserve the quality of the global model despite the diversity of local datasets.

Each of these methods represents an evolution in FL, introducing unique adjustments to the aggregation process to enhance convergence, reduce communication overhead, and improve robustness against adversarial clients and non-IID data conditions.

Building on the foundational principles of \ac{fl} methods detailed previously, we now turn our focus towards specialized neural network architectures that leverage these \ac{fl} strategies under unique operational constraints. A particularly interesting area is the utilization of \ac{snn}s, which offer a biologically inspired alternative to traditional Artificial Neural Networks (ANNs). SNNs are well-suited for on-device learning in edge computing scenarios due to their efficient energy consumption and capability for processing temporal information. However, the deployment of SNNs in such environments is not without challenges, primarily due to the limited data available on individual devices, which could significantly constrain the learning capabilities.

The limitations imposed by on-device training of \ac{snn}s, due to the constrained data availability on each device, is studied in \cite{Ch_1_R2}. Based on the results, the limitation can be mitigated through cooperative training utilizing \ac{fl}. An online FL-based learning rule, termed FL-SNN, for networked on-device SNNs is introduced. Through this scheme, local feedback signals are utilized within each SNN instead of backpropagation, and global feedback is facilitated through communication via a base station, showcasing the potential to significantly enhance training over isolated approaches by enabling a flexible compromise between communication load and accuracy through selective synaptic weight exchange.

A novel approach of selective model aggregation in \ac{fl} within the context of Vehicular EDGE Computing (VEC) is explored in \cite{Ch2_R40}. This approach focuses on the unique challenges posed by the diversity in image quality and computational capacity of vehicular clients for image classification. The approach, which selectively aggregates `fine' local DNN models based on an evaluation of local image quality and computation capability without compromising client privacy, employs two-dimensional contract theory for model selection due to the central server's unawareness of these local parameters. This methodology is shown to outperform conventional federated averaging in terms of accuracy and efficiency on the MNIST and BelgiumTSC datasets, also offering higher utility at the central server.

The paper by \cite{Ch2_R41} discusses a novel approach for fast global model aggregation in \ac{fl} via cloud computation, aiming to address the primary bottleneck of limited communication bandwidth in the aggregation of locally computed updates across devices with strict latency and privacy requirements, like drones and smart vehicles. This approach, employing a sparse and low-rank optimization problem solution through a Difference-of-Convex-functions algorithm for joint device selection and beamforming design, demonstrates significant algorithmic advantages and performance improvements in numerical results.

According to \cite{Ch2_R42}, \ac{fl} is suggested as a solution to the challenges faced in training machine learning models on IoT data due to constraints in network bandwidth, storage, and privacy. The focus is on how existing work has primarily centered on learning algorithms' convergence time, leaving issues like incentive mechanisms largely unexplored. A deep reinforcement learning-based incentive mechanism is proposed to motivate edge nodes towards model training contribution, with its efficiency validated through numerical experiments.

In \cite{Ch_1_R4}, the exploration of synergies between wireless communications and artificial intelligence, particularly the challenges of implementing ML models on battery-powered devices connected via bandwidth-constrained channels, is discussed. The paper highlights how \ac{fl} for distributed training of SNNs and the integration of neuromorphic sensing with SNNs can help overcome these challenges.

The research presented in \cite{Ch_1_R1} introduces a \ac{fl} method designed for training decentralized and privacy-preserving SNNs, focusing on the energy efficiency advantages of SNNs in \ac{fl} scenarios across energy-constrained devices. The method's effectiveness is experimentally validated through improved accuracy and energy efficiency in comparison to ANNs on CIFAR10 and CIFAR100 benchmarks.

A comprehensive study on deploying distributed learning over wireless edge networks, highlighting the challenges and emerging paradigms like \ac{fl} and distributed inference, is provided in \cite{Ch2_R43}. It presents an overview of communication techniques for efficient deployment and future research opportunities within wireless networks.

The effect of user selection and resource allocation on the convergence time and accuracy of \ac{fl} over wireless networks was investigated in \cite{Ch2_R44}. A probabilistic user selection scheme is proposed alongside the use of ANNs to estimate unselected users' local FL models, showing a reduction in convergence time and improvement in model accuracy through simulations.

Federated deep learning approaches for cybersecurity in IoT applications are reviewed and experimentally analyzed in \cite{Ch2_R45}. The article highlights the superiority of \ac{fl} in preserving IoT device data privacy and enhancing attack detection accuracy across various deep learning models.

The challenge of training \ac{fl} algorithms over wireless networks is studied in \cite{Ch2_R46}, where the impact of wireless factors on training quality and the optimization of learning, wireless resource allocation, and user selection to minimize FL loss function are discussed. Simulation results demonstrate the effectiveness of the proposed framework in improving identification accuracy.

In \cite{Ch2_R47}, an investigation is conducted into the allocation of energy-efficient transmission and computation resources for \ac{fl} over wireless communication networks. The model considered involves users training local FL models with their data and sending these to a base station (BS), which then aggregates these models and broadcasts the aggregated model back to the users. The optimization problem formulated aims to minimize total energy consumption under a latency constraint, with an iterative algorithm proposed that derives closed-form solutions for various parameters at every step. Initial feasible solutions are generated through a bisection-based algorithm aimed at minimizing completion time. It is shown through numerical results that energy consumption can be reduced by up to 59.5\% compared to conventional FL methods.

In \cite{Ch_1_R9}, a lead federated neuromorphic learning (LFNL) technique is proposed, designed as a decentralized, energy-efficient, brain-inspired computing method utilizing \ac{snn}s. This technique allows edge devices to collaboratively train a global model, preserving privacy and significantly reducing both data traffic and computational latency, with only a slight accuracy loss reported. The efficacy of LFNL in reducing energy consumption while maintaining competitive recognition accuracy, despite uneven dataset distribution, is demonstrated through experimental results.

The aggregation strategies in \ac{fl} through a comprehensive mathematical convergence analysis, leading to the derivation of novel aggregation algorithms that adapt model architecture by differentiating client contributions based on loss values, is presented in \cite{Ch2_R49}. This approach, which extends beyond theoretical assumptions to practical performance evaluations, is compared with the conventional FedAvg method across both IID and non-IID settings without additional hypotheses.

An edge-based backhaul (BH) selection technique aimed at improving traffic delivery by leveraging multiobjective feedback, utilizing advantage-actor-critic deep reinforcement learning methods, is introduced in \cite{Ch2_R50}. To enhance DRL training performance in large-scale IoT system deployments, \ac{fl} is applied, enabling collaboration among multiple edge devices. The effectiveness of this federated DRL approach in solving the BH selection problem is verified through extensive simulations.

In \cite{Ch2_R51}, a hierarchical trajectory planning method named HALOES, which employs deep reinforcement learning within a \ac{fl} scheme, is proposed for efficient, automatic parking in narrow spaces. This method combines high-level deep reinforcement learning with low-level optimization, improving planning time and model generalization capabilities while protecting data privacy during model parameter aggregation. Simulation results affirm HALOES's efficiency in various narrow-space parking scenarios.

The hierarchical \ac{fl} paradigm of HiFL is discussed in \cite{Ch2_R52}, which aims to mitigate communication overhead in FL systems by integrating synchronous client-edge and asynchronous edge-cloud model aggregations. An enhanced design, HiFlash, incorporates adaptive staleness control and a heterogeneity-aware client-edge association strategy through deep reinforcement learning, demonstrating improved system efficiency, communication reduction, and maintained model accuracy in experiments.

A survey on poisoning attacks and defense strategies in \ac{fl} from a privacy-preserving perspective, classifying and analyzing poisoning attacks and defense mechanisms, is provided in \cite{Ch2_R53}. The paper highlights the urgency of defending against poisoning attacks and suggests potential research directions for both attack and defense strategies, emphasizing the need for systematic reviews in this area.







% Introduction from Cahpter 4 ____________________________________________________________________________________________________

Autonomous docking of multiple agents in close-proximity missions—such as on-orbit servicing, satellite formation flying, and swarm payload alignment—poses unique challenges in precision, robustness, and energy efficiency. In these missions, a team of robots must cooperate without centralized control, perceive relative pose information under stringent bandwidth and latency constraints, and execute coordinated maneuvers despite dynamic uncertainties and limited onboard resources. To address these challenges, this paper introduces a fully decentralized, vision-based docking framework for swarm robots, combining \ac{dvs} event streams, \ac{alm}s, and a Deep \ac{snn} trained with \ac{stdp}. By leveraging the sparse, asynchronous output of \ac{dvs} cameras alongside bio-inspired learning rules, our approach achieves low-latency, energy-efficient control policies for reliable proximity docking in multi-agent settings.

The synchronization and coordination of multi-agent systems (MAS) are central to formation tasks in space docking missions, with leader-following consensus often achieved using event-triggered impulsive control for fast agreement without continuous communication \cite{tan2019consensus}, or dynamic event-triggered mechanisms with auxiliary variables to prevent Zeno behavior and reduce bandwidth usage in spacecraft clusters \cite{du2020dynamic}. Fixed-time consensus schemes ensure convergence within a specified time, supporting tightly synchronized docking maneuvers \cite{liu2020fixedtime}. Formation control under strict timing and resource constraints has progressed through neural-network-based and adaptive methods, including event-based adaptive neural network controllers using radial basis function networks to handle nonlinear uncertainties \cite{cao2024event} and adaptive tracking controls that integrate disturbance observers and event-triggered thresholds for maintaining performance with minimal updates \cite{zhang2020eventtriggered}. Deep learning has further enhanced MAS control, with centralized training and decentralized execution in deep reinforcement learning proving effective for complex coordination tasks such as distributed assembly and formation \cite{nguyen2020deep}. In contrast, event-triggered adaptive control for nonaffine dynamics and fully distributed NN-based adaptive control enable reduced communication and asymptotic synchronization in heterogeneous spacecraft formations \cite{liang2021neural, shen2020neural}. Robustness to sensor faults, input saturation, and precise timing remains essential in docking, which is achieved through event-triggered controllers using Nussbaum functions and barrier Lyapunov methods \cite{liu2021event}, alongside prescribed-time consensus frameworks that enable strict temporal adherence in docking sequences \cite{wang2019prescribed}.

Autonomous docking has been extensively studied across marine, aerial, and space domains. Vision-based pose estimation techniques have first demonstrated the real-world docking of work-class Remotely Operated Vehicles (ROVs) to both static and dynamic transportation management system platforms, using asymmetrically arranged LED beacons and multi-step image processing integrated with PID control loops \cite{Trslic2020}. Monocular vision systems with novel attitude estimators and particle‐filter trackers have similarly enabled high‐accuracy docking of hovering autonomous underwater vehicles, maintaining continuous marker visibility even under partial occlusion \cite{Figueiredo2020}. These approaches highlight the potential of lightweight vision sensors for proximity operations where acoustic methods may be limited.

In spacecraft applications, adaptive controllers enforcing time‐varying state constraints have been shown to guarantee safe payload‐carrying docking despite unknown mass variations, by employing Barrier Lyapunov Functions to bound position and velocity errors within decaying envelopes \cite{Sankaranarayanan2025}. Hardware tests on planar air-bearing platforms confirmed that such adaptive schemes outperform unconstrained methods under significant disturbances —a critical requirement for on-orbit servicing missions, where safety is paramount.

Geometric and potential‐based guidance laws have enabled cooperative docking between aerial vehicles. Quadrotor pairs employed artificial potential functions for approach guidance and nonlinear SE(3) controllers for precise port alignment during docking, demonstrating effective mutual maneuvering in simulation \cite{Nikhilraj2025}. Similarly, VTOL UAVs docking to mobile manipulators achieved on-site recharging through a hybrid visual-servoing and path planning framework, fusing predictive and reactive control to maintain a line of sight and ensure a secure attachment \cite{Narvaez2021}.

Formation control frameworks extended docking capabilities to heterogeneous mobile robot teams. A subsumption architecture combined layered kinematic objectives with robust dynamic controllers to manage autonomous docking, formation switching, and collision avoidance under model uncertainties, verified in simulation with up to a dozen robots \cite{Lashkari2020}. Compact self-assembling modules with parallel-gripper docking and onboard visual perception further illustrate scalable docking and reconfiguration for modular robot chains traversing complex terrains \cite{Li2022}.

In structured environments, sensor-fusion and learning-based methods have improved docking precision. YOLOv7-based detection, fused with LiDAR alignment, enabled robust industrial mobile robot recharging, achieving real-time recognition and sub-decimeter positioning in manufacturing settings \cite{Jia2023}. Regression-based monocular systems trained on LiDAR ground truth can influence ArUco marker distortions to estimate distance and orientation with centimeter-level accuracy, vastly outperforming SolvePnP methods while using only low-cost cameras \cite{Oh2025}.

While these model-based and vision-driven controllers provide strong performance in defined scenarios, proximity missions in space docking—characterized by time-varying dynamics, unforeseen disturbances, and energy constraints—require more adaptive, data-driven control architectures. \ac{snn}s trained via the Reinforcement Learning (RL) paradigm can learn end‐to‐end docking policies from sensory inputs, offering fast inference, on‐chip adaptability, and robustness to unmodeled effects. 

% Deep SNN

RL paradigms in \ac{snn}s enable agents to learn control policies through trial-and-error interactions, a capability crucial for autonomous proximity operations in space docking. Bio-plausible learning rules, such as Spike-Timing-Dependent Plasticity (STDP) combined with reward signals, have been shown to approximate backpropagation and support multi-layer learning \cite{TavanaeiMaida2018BPSTDP, AnwaniRajendran2020NormAD, TaherkhaniBelatreche2018BPSL}. By incorporating eligibility traces and global reward feedback, these methods allow \ac{snn}s to adjust synaptic weights in response to docking success metrics, facilitating rapid adaptation to new docking trajectories.

Scaling RL-trained \ac{snn} architectures to deep networks requires addressing vanishing spike activity and ensuring information propagation across layers. Techniques such as Spike Activation Lift Training (SALT) and Switched-BN enhance spike throughput in very deep \ac{snn}s, improving learning capacity under RL-like reward cues \cite{KimPanda2021SALT}. Likewise, weighted spikes encode multi-bit information per event, reducing decision latency—an essential factor for timely thruster commands during docking \cite{KimHuh2018Weighted}. These advances pave the way for deep \ac{snn}s that learn complex docking maneuvers through RL while maintaining low energy consumption.

Proximity missions impose strict hardware constraints on power, area, and latency. Neuromorphic signal‐processing systems that employ ternary spike encoding and quantized \ac{snn}s achieve substantial memory and energy savings, making on-board RL plausible \cite{WangZhang2025Ternary, LinYuan2020ReRAM}. In-memory ReRAM-based architectures with ternary deep \ac{snn}s further reduce data movement and support fast synaptic updates under RL protocols \cite{LinYuan2020ReRAM}. Such hardware platforms can host RL-trained \ac{snn} controllers directly on spacecraft avionics, offering robust, low-power autonomy.

Accurate temporal and spatial precision is vital for docking proximity control. Fractional‐order STDP (FO‐STDGD) enhances gradient descent in \ac{snn}s, improving convergence speed and accuracy in gesture‐like input scenarios analogous to docking sensor streams \cite{YangVoyles2025FOSTDGD}. Biologically plausible multi‐spike learning algorithms integrate synaptic delay training to fine‐tune event timing, enabling precise control of approach velocities and alignment \cite{TaherkhaniBelatreche2018BPSL}.

Optimizing the training pipeline further accelerates RL convergence in \ac{snn}s. Parameter initialization based on neuronal response asymptotes prevents vanishing gradients, enabling deeper RL‐trained \ac{snn}s to learn docking policies from sparse reward signals \cite{DingZhang2025Init}. Modeling ANN‐\ac{snn} conversion residuals as additive noise yields low‐latency networks that maintain policy fidelity under time constraints \cite{HuangDing2025Residual}. Hybrid training methods that jointly optimize membrane leak, thresholds, and weights reduce inference timesteps to a few ms\cite{XuLi2021DIET}.

These advances in RL‐trained \ac{snn}s—spanning learning rules, deep architectures, neuromorphic hardware, temporal precision, and training optimizations—provide a unified foundation for developing energy‐efficient, low‐latency controllers for space docking proximity missions. \ac{dvs} cameras can supply sparse, event‐driven input streams to these \ac{snn} controllers, further enhancing their responsiveness and energy efficiency in docking scenarios.

% DVS 

\ac{dvs}s offer a fundamentally different paradigm from conventional frame-based cameras by asynchronously encoding pixel-level brightness changes as a sparse stream of events, yielding microsecond-scale temporal resolution and minimal data redundancy. This event-driven operation allows \ac{dvs} to detect fast motions with latencies as low as 3 milliseconds, while consuming only a fraction of the power needed by CMOS imagers \cite{Lee2014RealTimeGesture,Seifozzakerini2018Hough}. The high dynamic range (up to 120 dB) of \ac{dvs} further enables reliable operation under extreme illumination variations without saturating the sensor \cite{Seifozzakerini2018Hough,Bichler2012Extraction}. These attributes are particularly advantageous for proximity operations in space docking, where rapid, energy-efficient sensing of relative motion is critical.

\ac{snn}s naturally complement \ac{dvs} by processing event streams natively through time-encoded spikes, enabling highly efficient feature extraction and pattern recognition. Early work demonstrated that the STDP can robustly learn temporal correlations from raw \ac{dvs} data, extracting motion patterns such as vehicle trajectories with minimal synaptic complexity and high noise tolerance \cite{Bichler2012Extraction,Thiele2018EventBased}. Architectures with localized lateral inhibition have been shown to learn hierarchical features in a single pass, achieving an accuracy above 96\,\% with only one presentation of the data \cite{Thiele2018EventBased,Zhao2014Feedforward}.

Recent advances have expanded \ac{dvs}–\ac{snn} systems to more complex applications relevant to autonomous navigation and control. For instance, deep convolutional \ac{snn}s trained with surrogate gradients achieve competitive object localization accuracy with up to 126× energy savings compared to ANNs \cite{Barchid2023Localization,Zanatta2023Directly}. In RL scenarios, directly-trained \ac{snn}s on neuromorphic accelerators have shown superior generalization for UAV obstacle avoidance, reaching goals 98\,\% of the time while consuming an order of magnitude less energy than CNN counterparts \cite{Zanatta2023Directly,Salt2019Parameter}. Event-based action recognition using novel benchmarks, such as \ac{dvs}-Gesture-Chain, highlights the inherent temporal processing advantages of \ac{snn}s, enabling feed-forward networks to perceive event sequences without recurrent connections \cite{VicenteSola2024SpikingAction,Zanatta2023Directly}.

For space docking missions, precise detection of geometric features such as planar edges and circular apertures is essential for alignment and approach control. Event-based adaptations of the Hough Transform implemented in \ac{snn}s allow real-time line detection and 3D parameter estimation directly on \ac{dvs} outputs with no external memory or CPU, significantly reducing latency and power consumption \cite{Seifozzakerini2018Hough}. Self-supervised information bottleneck learning further enhances event-based optical flow estimation, improving robustness to noise and reducing energy usage by over 90\,\% compared to ANN methods \cite{Yang2024SelfSupervised}. These capabilities suggest that \ac{dvs}–\ac{snn} pipelines can provide the low-latency, low-power sensing and processing required for autonomous proximity operations in on-orbit docking scenarios.