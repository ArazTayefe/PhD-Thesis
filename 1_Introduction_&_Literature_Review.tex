\chapter{Introduction}

\ac{snn}s represent the third generation of neural models, operating with discrete spikes that carry both temporal and spatial information. Unlike conventional neural networks that rely on continuous activations, \ac{snn}s process asynchronous event streams, providing rich temporal dynamics and exceptionally low power consumption. These characteristics make \ac{snn}s highly suitable for edge intelligence, real-time robotics, and distributed autonomous systems, where energy efficiency and reaction speed are critical \cite{Ch_1_R2, Ch_1_R3}.

A major advantage of \ac{snn}s lies in their biologically grounded learning mechanisms. Local plasticity rules such as \ac{stdp} and reward-modulated STDP enable online adaptation without requiring global error signals. These mechanisms allow \ac{snn}s to learn from sparse, delayed, or noisy feedback—conditions commonly encountered in multiagent control. Recent progress in deep \ac{snn} architectures extends these ideas by stacking multiple spiking layers, enabling hierarchical feature extraction from high-dimensional sensory streams. However, training deep \ac{snn}s remains challenging due to non-differentiability of spikes, temporal credit assignment, and instability of multi-layer plasticity.

To address these challenges, this thesis develops adaptive hierarchical learning algorithms for deep \ac{snn}s, combining structured modularity with reward-based plasticity. The proposed models integrate both local \ac{stdp} mechanisms and temporal population coding, allowing deeper layers to form stable representations while earlier layers handle fast, event-driven signals such as those from \ac{dvs}. These contributions enable \ac{snn}s to learn complex perception–action loops, maintain short-term temporal memory, and operate robustly in dynamic multiagent environments.

In multiagent systems, one of the main strategies for sharing knowledge across distributed agents is \ac{fl}. The \ac{fl} is a decentralized training framework where agents exchange model updates instead of raw data. In this thesis, \ac{fl} is integrated with spiking neural networks to enable collaborative learning across multiple event-driven agents, allowing each deep SNN to adapt locally via R-STDP while periodically contributing its learned synaptic structure to a global model without violating bandwidth or energy constraints. \ac{fl} enables distributed agents to train collaboratively without sharing raw sensory data, preserving privacy and reducing communication loads—qualities particularly relevant for energy-constrained robotic platforms. When combined with the sparse, event-driven nature of \ac{snn}s, \ac{fl} can reduce bandwidth requirements and support decentralized learning across heterogeneous devices \cite{Ch_1_R4, Ch_1_R5}.

Developing effective training methods for deep spiking neural networks remains an open research challenge, largely due to the non-differentiable nature of spikes, the temporal dependencies across layers, and the difficulty of assigning credit in multi-stage processing pipelines. Existing approaches struggle to balance biological plausibility, computational efficiency, and scalability to deeper architectures. In this thesis, a hierarchical SNN framework is explored in which layered processing, reward-modulated plasticity, and attention-guided reinforcement work together to address these limitations.


%  \ac{\ac{snn}}s are a class of neural models inspired by the event-driven signaling of biological neurons. Unlike conventional artificial neural networks, \ac{snn}s process information through discrete spikes, enabling efficient temporal coding and low-power operation. This event-driven paradigm makes \ac{snn}s particularly suitable for edge computing and real-time control tasks, where responsiveness and energy efficiency are critical \cite{Ch_1_R2, Ch_1_R3}.

% Recent advances in \ac{snn}s have demonstrated their ability to learn complex behaviors using biologically plausible mechanisms such as \ac{stdp} and reward-modulated learning. These features allow \ac{snn}s to adapt to dynamic environments and perform robustly under sparse or delayed feedback, making them attractive for multiagent reinforcement learning and autonomous systems.

% \ac{fl} complements \ac{snn}s by enabling decentralized training across distributed devices without sharing raw data. In FL, each agent trains its local model and periodically exchanges updates with a central server or among peers, preserving privacy and reducing communication overhead. The combination of \ac{snn}s and FL supports scalable, privacy-preserving, and energy-efficient learning in multiagent systems, especially in scenarios where data locality and resource constraints are important.

% The energy-efficient nature of \ac{snn}s aligns perfectly with the objectives of \ac{fl}, where models are trained across a network of distributed devices without centralized data collection. Unlike conventional artificial neural networks that require continuous data flow and computation, \ac{snn}s' event-driven operation allows for significant reductions in energy consumption, which is critical for battery-operated agents participating in \ac{fl}. This characteristic of \ac{snn}s supports the development of low-power, distributed learning solutions, enabling more agents to participate in \ac{fl} without compromising on power efficiency \cite{Ch_1_R4}.

% Furthermore, the integration of \ac{snn}s in \ac{fl} scenarios can also help overcome limitations associated with bandwidth-constrained environments. The sparse nature of data representation and communication in \ac{snn}s means that less information needs to be exchanged between devices and the central server during the training process. This efficiency is crucial in \ac{fl} environments, where network bandwidth and connectivity can significantly impact the feasibility and performance of distributed learning systems \cite{Ch_1_R5}.

% Another critical advantage of \ac{snn}s in the context of \ac{fl} is their compatibility with neuromorphic hardware. Neuromorphic chips, designed to replicate the neural structures of the human brain, provide an ideal platform for deploying \ac{snn}s. This synergy between neuromorphic computing and \ac{snn}s paves the way for the development of highly efficient, scalable, and adaptive \ac{fl} systems capable of leveraging the full potential of edge computing \cite{Ch_1_R6}.

% Despite these advantages, the integration of \ac{snn}s with \ac{fl} presents several challenges. The primary hurdle is the complexity of training \ac{snn}s in complex problems. The dynamic and temporal nature of \ac{snn}s introduces new challenges in developing effective \ac{fl} protocols that can accommodate the unique online learning rules of \ac{snn}s. Proper scheduling of communication rounds within the local \ac{snn} time steps is essential for successful collaborative training \cite{Ch_1_R7}.

% Moreover, managing the performance trade-offs associated with the frequency of communication rounds in \ac{fl} is another significant challenge. Experiments have shown the impact of the number of time steps between local updates and the frequency of model aggregation on the training performance of \ac{snn}s. Finding an optimal balance to maximize model performance while minimizing communication overhead is crucial for the efficient deployment of \ac{fl} systems powered by \ac{snn}s \cite{Ch_1_R8}.

% Additionally, communication constraints and the non-stationarity of data distribution pose significant challenges. The need for larger model update intervals to reduce communication costs and the changing nature of data over time (e.g., reward function in RL) require innovative solutions to maintain the accuracy and reliability of \ac{fl} systems employing \ac{snn}s \cite{Ch_1_R9}.

% Despite these challenges, the potential benefits of integrating \ac{snn}s with \ac{fl} justify continued research and development in this area. The combination of energy efficiency, privacy preservation, and compatibility with neuromorphic hardware, along with the distributed and collaborative nature of \ac{fl}, represents a compelling approach to deploying machine learning models in real-world applications \cite{Ch_1_R10}.


\section{Spiking Neural Networks: Models and Learning Algorithms}

\subsection{Neuron model}

In the study of computational neuroscience and the development of neural networks, particularly \ac{snn}, various neuron models have been proposed to simulate the electrical activity of neurons. These models range from simple to complex, aiming to capture the essential features of neuronal dynamics. The diagram in Figure \ref{Fig.SimplMdlSNN} illustrates a basic network consisting of spiking neurons. In this network, the pre-synaptic neuron (pre-neuron) in the input layer spikes in response to the input (I) and transmits these spikes through synaptic weights to the post-synaptic neuron (post-neuron). Whenever the pre-neuron spikes, the post-neuron receives input current with a value of W.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Figures/Simple Spiking Neural Network.pdf}
    \caption{Simple model of a \ac{snn}. The spike pattern shows that the neurons spike whenever the voltage of the neuron reaches a threshold.}
    \label{Fig.SimplMdlSNN}
\end{figure}

Table \ref{Table.SRF} shows the differential equations used in the network. In \ac{snn}s, the activation function, like ReLu and tanh in regular neural networks, is replaced by a differential equation that mimics the biological neuron activity.

\begin{table}[H]
    \centering
    \begin{tabular}{cc}
        \toprule
        & \textbf{Spike Response Function} \\
        \midrule
        \textbf{Pre-Neuron} & $\dot{V}_1 = \frac{1}{\tau_m} \left[ E_L - V_1 + R_m I \right]$ \\
        \midrule
        \textbf{Post-Neuron} & $\dot{V}_2 = \frac{1}{\tau_m} \left[ E_L - V_2 + R_m \left( W \delta (t - t_{\text{pre}}) \right) \right]$ \\
        \bottomrule
    \end{tabular}
    \caption{Spike Response Function of the neurons in an \ac{snn}.}
    \label{Table.SRF}
\end{table}

Several spike response functions have been proposed to emulate neuron activity. In this chapter, the Leaky-Integrate and Fire model is represented because it is simple and accurate enough in emulating real neurons. This section overviews the neuron model and its characteristics.


\subsubsection{Leaky-Integrate and Fire model}
The \ac{lif} model is a biological model that can be represented as a circuit with a resistor and capacitor and represents a first-order dynamic system \cite{Ch_1_R13},

\begin{equation} \label{Eq.1}
    R_{m}C_{m}\frac{dV_m\left(t\right)}{dt} = E_{l} - V_m\left(t\right) + R_{m}I\left(t\right)
\end{equation}

\noindent where $V_{m}(t)$ is the neuron's membrane potential shown as \(V_{1}\) and \(V_{2}\) in Table \ref{Table.SRF}, $R_{m}$ is the membrane resistance, $C_{m}$ is the membrane capacitance, $E_{l}$ is the resting potential, and $I(t)$ is the input current. The neuron spikes when its potential reaches the threshold potential ($V_{th}$). The potential of the neuron immediately reaches the reset potential ($V_{res}$) after it spikes.

The spike rate is a parameter that determines how fast the neuron spikes \cite{Ch_1_R11}.

\begin{equation} \label{Eq.4}
    r_{[Hz]} = \frac{1}{t_{isi}\enspace [s]}
\end{equation}

\noindent where $t_{isi}$ is the inter-spike interval that can be calculated using the neuron model, when the potential of a neuron reaches the threshold potential, it fires. Therefore, based on the analytical solution of (\ref{Eq.1}), the inter-spike interval time can be written as,

\begin{equation} \label{Eq.7}
    t_{isi} = \tau_{m}\ln\left(\frac{E_{l} + R_{m}I - V_{res}}{E_{l} + R_{m}I - V_{th}}\right)
\end{equation}

\noindent where $\tau_{m}$ is the membrane time constant. 

According to (\ref{Eq.7}), the following condition should be satisfied to have a finite value for $t_{isi}$,

\begin{equation} \label{Eq.8}
    E_{l} + R_{m}I - V_{th} > 0
\end{equation}

\noindent or

\begin{equation} \label{Eq.9}
    I > \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

\noindent which means that the input current higher than the above value generates spikes. 

After calculating the minimum input for neurons, we must find the maximum input based on the inter-spike interval. Equation (\ref{Eq.7}) can be written as,

\begin{equation} \label{Eq.10}
    t_{isi} = \tau_{m}\ln\left(1+\frac{V_{th} - V_{res}}{E_{l} + R_{m}I - V_{th}}\right)
\end{equation}

\noindent Equation (\ref{Eq.10}) can be approximated using the Maclaurin series for the natural logarithm function ($\ln(1+z)\approx z$) as follows,

\begin{equation} \label{Eq.11}
    t_{isi} = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{E_{l} + R_{m}I - V_{th}}
\end{equation}

\noindent Solving for $I$, an input current as a function of the inter-spike interval can be obtained,

\begin{equation} \label{Eq.12}
    I = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{t_{isi}R_{m}} + \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

The maximum value for the input current makes the neuron fire at each sample time ($\Delta t$). Therefore, the maximum input current is,

\begin{equation} \label{Eq.13}
    I^{max} = \frac{\tau_{m}\left(V_{th} - V_{res}\right)}{\Delta t R_{m}} + \frac{V_{th} - E_{l}}{R_{m}}
\end{equation}

In this section, we obtained the minimum and maximum values for input current using (\ref{Eq.9}) and (\ref{Eq.13}). These equations are used in the learning and encoding processes of the \ac{snn}.

\subsection{Izhikevich model}
The Izhikevich model is a widely used spiking neuron model that balances biological plausibility with computational efficiency. It captures a variety of neuronal firing patterns observed in real neurons while remaining relatively simple to implement. The model is defined by the following set of differential equations \cite{Ch_1_R14}:
\begin{equation}
    \frac{dV}{dt} = 0.04V^2 + 5V + 140 - U + I
\end{equation}
\begin{equation}
    \frac{dU}{dt} = a(bV - U)
\end{equation}
\noindent where \(V\) represents the membrane potential of the neuron, \(U\) is a recovery variable that accounts for the activation of potassium ionic currents and inactivation of sodium ionic currents, and \(I\) is the input current. The parameters \(a\), \(b\), \(c\), and \(d\) are dimensionless constants that can be adjusted to model different types of neurons. The model also includes a reset mechanism that occurs when the membrane potential \(V\) reaches a certain threshold (typically 30 mV):
\begin{equation}
    \text{if } V \geq 30 \text{ mV, then } 
    \begin{cases}
        V \leftarrow c \\
        U \leftarrow U + d
    \end{cases}
\end{equation}
The Izhikevich model is capable of reproducing a wide range of neuronal behaviors, including regular spiking, bistability spiking, bursting, and chattering, by appropriately tuning the parameters \(a\), \(b\), \(c\), and \(d\). This versatility makes it a popular choice for simulating large-scale neural networks while maintaining a reasonable level of biological realism.


\subsection{Learning Approaches in SNNs}

\subsection*{Hebbian Learning}


Hebbian Learning is a fundamental neural learning principle summarized by the axiom ``neurons that fire together, wire together," describing how simultaneous activation of neurons leads to strengthened connections between them~\cite{Ch_1_R16}. Hebbian learning, particularly within the context of \ac{snn}, primarily revolves around the modulation of synaptic strengths based on the firing rates of pre- and postsynaptic neurons. The principles of locality and joint activity are fundamental, emphasizing that synaptic changes occur only when both neurons are active simultaneously.

\textbf{Methods of Synaptic Modification:}
\begin{itemize}
    \item \textbf{Local Rules:} Synaptic changes are influenced directly by the activities of the connecting neurons without external influences.
    \item \textbf{Bounded Growth:} To avoid uncontrolled increases in synaptic strength, models typically incorporate mechanisms such as hard and soft bounds. Hard bounds prevent any further increase once a maximum weight is achieved, while soft bounds slow down the rate of increase as the maximum is approached~\cite{Ch_1_R25}.
    \item \textbf{Synaptic Decay:} Realistic models also consider mechanisms for reducing synaptic strengths, typically through a decay term that weakens connections in the absence of activity~\cite{Ch_1_R17}.
\end{itemize}

\textbf{Advanced Hebbian Models:}
\begin{itemize}
    \item \textbf{Covariance Rule:} This model refines the synaptic modification to depend on the deviation of firing rates from their means, enhancing the dynamic response of synapses to changes in neural activity~\cite{Ch_1_R32}.
    \item \textbf{Oja's Rule:} A self-stabilizing rule that ensures synaptic weights do not grow indefinitely by normalizing the weight vector, thereby maintaining the overall stability of the network~\cite{Ch_1_R19}.
    \item \textbf{BCM Rule:} The Bienenstock-Cooper-Munro rule introduces an adaptive threshold for synaptic modification, which evolves based on the historical activity of the neuron, allowing for more refined potentiation and depression based on relative activity levels.~\cite{Ch_1_R31}.
    \item \textbf{RCHP:} Rarely Correlating Hebbian Plasticity focuses on synaptic changes driven by rare, significant coincidences in neuronal activity, aiming to strengthen connections that are crucial for neural function while avoiding over-strengthening due to common activity patterns~\cite{Ch_1_R20}.
\end{itemize}

\textbf{Incorporation into Reinforcement Learning:}
Modern adaptations in \ac{snn}s integrate the concept of rewards, adding a third dimension to synaptic adjustments. This integration uses scaling or gating mechanisms in response to global reward signals, further refining the learning capabilities of neural networks based on external feedback.


\subsection*{Neo-Hebbian Learning and Modulation Mechanisms}

In neo-Hebbian reinforcement learning, significant advancements come from a global reward signal modulating synaptic plasticity alongside an eligibility trace that decays over time~\cite{Ch_1_R21}. This trace increases with recent, successful neurotransmission and decreases as time passes, linking closely with Temporal-Difference (TD) learning mechanisms. Such dynamics allow for Long-Term Potentiation (LTP) or Depression (LTD) at synapses based on the timing of synaptic activity and the nature of the reward signal. Specifically, recent successful activities followed by positive rewards enhance LTP, while activities preceding negative rewards lead to LTD.



\textbf{Distal rewards and credit assignment} 

This model introduces a sophisticated approach to synaptic modification through the interaction of \ac{stdp} with a modulatory reward signal, embodying the essence of TD learning within the realm of spiking neurons.


Central to this framework is the eligibility trace mechanism, elegantly adapted from its conventional application in TD learning to facilitate synaptic credit assignment over varying temporal horizons. This adaptation allows for the dynamic modulation of synaptic strengths based on the timing and sequence of pre- and post-synaptic spikes, in conjunction with the temporal dynamics of received rewards. The eligibility trace is mathematically represented as follows~\cite{Ch_1_R22}:

\begin{equation}
    \frac{dC_{ji}}{dt} = -\frac{C_{ji}}{\tau_{C}} + \text{STDP}(t_{\text{post}} - t_{\text{pre}})\delta(t - t^{(f)})
\end{equation}

Here, $C_{ji}(t)$ denotes the eligibility trace for the synapse between pre-synaptic neuron $j$ and post-synaptic neuron $i$, evolving with a decay governed by $\tau_{C}$. The variables $t_{\text{pre}}$ and $t_{\text{post}}$ represent the most recent firing times of the pre- and post-synaptic neurons, respectively. The Dirac delta function, $\delta(t - t^{(f)})$, signifies the occurrence of a spike, serving as a pivotal factor in the temporal credit assignment process. 

The STDP function can be represented as follows,

\begin{equation}
    STDP(\tau) = \mathcal{A} \exp\left(-\frac{\tau}{\tau_{s}}\right) \text{for \(\tau \geq 0\)}, (\tau = t_{\text{post}} - t_{\text{pre}})
\end{equation}

\noindent where \(\mathcal{A}\) stands as the amplitude and \(\tau_{s}\) acts as the time constant.

Synaptic weight updates are then guided by the interaction between the eligibility trace and the reward signal, $R(t)$, as captured in the following equation:

\begin{equation}
    \frac{dw_{ji}}{dt} = C_{ji}(t) \cdot R(t)
\end{equation}

\noindent where $dw_{ji}/dt$ symbolizes the rate of change in synaptic weight, contingent upon the compounded influence of the eligibility trace and the reward signal.


\section{Literature Review}

% \subsection{Spiking Neural Network}

% \ac{snn}s have garnered significant attention for their ability to emulate complex neural dynamics observed in biological systems. This literature review focuses on the learning mechanisms, including STDP, and their implications in modeling biological learning behaviors.

% Besides the LIF model, there are different types of \ac{snn} models. The Hodgkin-Huxley model is a foundational framework in neuroscience that meticulously describes the ionic processes critical for the initiation and propagation of action potentials in neurons~\cite{Ch_1_R12}. The model uses differential equations to capture the dynamics of membrane potential (\(V\)) influenced by various ion-specific currents and gating variables, which regulate ion channel states. These gating variables, which transition between 0 and 1, reflect the proportion of ion channels in different states, crucial for mimicking the action potentials’ temporal complexity. In contrast, the FitzHugh-Nagumo model simplifies the complex Hodgkin-Huxley framework into a two-variable system, focusing on capturing the essential characteristics of neuronal excitability with fewer computational demands.

% The Izhikevich model merges the biological realism of the Hodgkin-Huxley model with the computational simplicity of integrate-and-fire models, offering a balanced approach for simulating neuronal behavior~\cite{izhikevich2003simple }. This model is particularly noted for its ability to produce diverse firing patterns with computational efficiency, making it suitable for simulating large networks of neurons while still capturing key aspects of neuronal activity.

% The learning in \ac{snn}s is based on the timing between neurons firing. The STPD process is one of the biological processes observed in real neurons. The investigation of competitive Hebbian learning through STDP reveals how the timing of spikes modulates synaptic efficacy, underscoring the significance of temporal dynamics in synaptic modification within neural circuits \cite{Ch2_R9}. This highlights the critical role of spike timing in learning processes, which is essential for understanding neural adaptation.

% In a significant study, the distal reward problem was tackled by linking STDP with dopamine signaling, illustrating a novel approach to reward-based learning in the brain \cite{Ch_1_R22}. This study proposed a model where dopamine modulates STDP mechanisms, effectively capturing the essence of reward-based learning processes.

% Another research posited that STDP emerges from fundamental learning rules governed by intracellular calcium dynamics, suggesting a deeper biophysical basis for synaptic strength regulation \cite{Ch2_R6}. This challenges the traditional understanding of STDP and points towards a more comprehensive framework for neural plasticity.

% An extensive review of the development and implications of STDP in neural circuits provided insights into its critical role in precise spike timing for synaptic modification, enriching our understanding of the neural basis for learning and memory \cite{Ch2_R5}. 

% A study on multiagent reinforcement learning within the Iterated Prisoner's Dilemma framework highlighted \ac{snn}s' comparable or enhanced performance against traditional models \cite{Ch2_R4}. This emphasizes the critical role of spike timing in complex decision-making processes, showcasing \ac{snn}s' potential in simulating interactive and competitive environments.

% The introduction of a model for parallel path planning using spiking neural activity, inspired by hippocampal navigation strategies, showcased the efficiency of \ac{snn}s in solving spatial navigation problems through biologically plausible mechanisms \cite{Ch2_R3}.

% In a pioneering study, the implementation of probabilistic inference within networks of LIF neurons demonstrated how Bayesian networks can be transformed into a computable framework for \ac{snn}s \cite{Ch2_R1}. This methodology underscores \ac{snn}s' capability to perform complex cognitive functions through probabilistic reasoning.

% The performance comparison between \ac{snn}s and multilayer perceptrons in a computer-based racing game highlighted \ac{snn}s' superior adaptability and decision-making capabilities in dynamic environments, attributed to the efficient processing of real-time data through spike-based mechanisms \cite{Ch2_R2}.

% Hierarchical Bayesian inference within \ac{snn}s introduces a learning algorithm based on synaptic plasticity, showcasing the ability of \ac{snn}s to execute complex tasks like pattern recognition through hierarchical structures \cite{Ch2_R14}. This emphasizes the adaptability and computational efficiency of \ac{snn}s.

% BP-STDP, which approximates backpropagation using STDP, bridges the gap between \ac{snn} mechanisms and traditional neural network computational efficiency \cite{Ch2_R16}. This algorithm advances learning algorithms for \ac{snn}s, making them more accessible for machine learning tasks.

% Indirect and direct training methods for \ac{snn}s in end-to-end control of a lane-keeping vehicle highlight the effectiveness of both approaches in utilizing \ac{snn}s for real-world control tasks, providing insights into training \ac{snn}s for complex systems like autonomous vehicles \cite{Ch2_R17}.

% N3-CPL, a neuroplasticity-based learning method for neuromorphic networks, focuses on cell proliferation in \ac{snn}s, enhancing learning capabilities through mechanisms inspired by biological neural network growth and adaptation \cite{Ch2_R18}.

% Parameter optimization in an \ac{snn} model for UAV obstacle avoidance tackles the challenge of tuning \ac{snn} parameters for specific tasks using optimization techniques, emphasizing the importance of optimization in \ac{snn} application for real-time processing and decision-making \cite{Salt2019Parameter}.

% A methodology for multi-task autonomous learning in mobile robots using \ac{snn}s was proposed, employing Modified Integrate-and-Fire and \ac{lif} neuron models, alongside a task switch mechanism inspired by lateral inhibition and a novel learning rule based on \ac{stdp}. This approach demonstrated \ac{snn}s' capabilities in efficiently learning and adapting across various tasks such as obstacle avoidance and target tracking \cite{Ch2_R20}.

% An autonomous learning framework that combines \ac{snn}s with a pre-trained binary Convolutional Neural Network for image-based reinforcement learning was developed. This hybrid model efficiently processes high-dimensional sensory data and learns from sparse rewards, highlighting the synergistic potential of \ac{snn}s and CNNs in complex visual environments \cite{Ch2_R21}.

% A transfer learning algorithm for \ac{snn}s aimed at deep learning tasks was introduced, utilizing Centered Kernel Alignment for domain distance measurement and focusing on domain-invariant representation. This methodology enables effective knowledge transfer, showcasing the scalability and adaptability of \ac{snn}s \cite{Ch2_R22}.

% Mathematical constraints influencing Hebbian learning and STDP in \ac{snn}s were explored, revealing relationships between synaptic weight promotion/demotion probabilities and normalized weights, offering insights into optimizing \ac{snn} training \cite{Ch2_R24}.

% ``Spikepropamine," incorporating differentiable plasticity within \ac{snn}s, was presented. This approach enables adaptive learning and improved task performance, signifying advancements in neuromorphic computing and robotics applications of \ac{snn}s \cite{Ch2_R25}.

% NeuronGPU, a library for simulating large-scale networks of spiking neurons with GPU acceleration, was developed. This tool demonstrated scalability and efficiency in simulating complex neuronal dynamics, marking a significant contribution to computational neuroscience tools \cite{Ch2_R26}.


% % Added from chapter 4_DVS_based_Docking.tex

% The synchronization and coordination of multi-agent systems (MAS) are central to formation tasks in space docking missions, with leader-following consensus often achieved using event-triggered impulsive control for fast agreement without continuous communication \cite{tan2019consensus}, or dynamic event-triggered mechanisms with auxiliary variables to prevent Zeno behavior, where an infinite number of events are triggered within a finite time interval, and reduce bandwidth usage in spacecraft clusters \cite{du2020dynamic}. Fixed-time consensus schemes ensure convergence within a specified time, supporting tightly synchronized docking maneuvers \cite{liu2020fixedtime}. Formation control under strict timing and resource constraints has progressed through neural-network-based and adaptive methods, including event-based adaptive neural network controllers using radial basis function networks to handle nonlinear uncertainties \cite{cao2024event} and adaptive tracking controls that integrate disturbance observers and event-triggered thresholds for maintaining performance with minimal updates \cite{zhang2020eventtriggered}. Deep learning has further enhanced MAS control, with centralized training and decentralized execution in deep reinforcement learning proving effective for complex coordination tasks such as distributed assembly and formation \cite{nguyen2020deep}. In contrast, event-triggered adaptive control for nonaffine dynamics and fully distributed NN-based adaptive control enable reduced communication and asymptotic synchronization in heterogeneous spacecraft formations \cite{liang2021neural, shen2020neural}. Robustness to sensor faults, input saturation, and precise timing remains essential in docking, which is achieved through event-triggered controllers using Nussbaum functions and barrier Lyapunov methods \cite{liu2021event}, alongside prescribed-time consensus frameworks that enable strict temporal adherence in docking sequences \cite{wang2019prescribed}.

% Autonomous docking has been extensively studied across marine, aerial, and space domains. Vision-based pose estimation techniques have first demonstrated the real-world docking of work-class Remotely Operated Vehicles (ROVs) to both static and dynamic transportation management system platforms, using asymmetrically arranged LED beacons and multi-step image processing integrated with PID control loops \cite{Trslic2020}. Monocular vision systems with novel attitude estimators and particle‐filter trackers have similarly enabled high‐accuracy docking of hovering autonomous underwater vehicles, maintaining continuous marker visibility even under partial occlusion \cite{Figueiredo2020}. These approaches highlight the potential of lightweight vision sensors for proximity operations where acoustic methods may be limited.

% In spacecraft applications, adaptive controllers enforcing time‐varying state constraints have been shown to guarantee safe Payload‐carrying docking despite unknown mass variations, by employing Barrier Lyapunov Functions to bound position and velocity errors within decaying envelopes \cite{Sankaranarayanan2025}. Hardware tests on planar air-bearing platforms confirmed that such adaptive schemes outperform unconstrained methods under significant disturbances, a critical requirement for on-orbit servicing missions, where safety is paramount.

% Geometric and potential‐based guidance laws have enabled cooperative docking between aerial vehicles. Quadrotor pairs employed artificial potential functions for approach guidance and nonlinear 3D controllers for precise port alignment during docking, demonstrating effective mutual maneuvering in simulation \cite{Nikhilraj2025}. Similarly, VTOL UAVs docking to mobile manipulators achieved on-site recharging through a hybrid visual-servoing and path planning framework, fusing predictive and reactive control to maintain a line of sight and ensure a secure attachment \cite{Narvaez2021}.

% Formation control frameworks extended docking capabilities to heterogeneous mobile robot teams. A subsumption architecture combined layered kinematic objectives with robust dynamic controllers to manage autonomous docking, formation switching, and collision avoidance under model uncertainties, verified in simulation with up to a dozen robots \cite{Lashkari2020}. Compact self-assembling modules with parallel-gripper docking and onboard visual perception further illustrate scalable docking and reconfiguration for modular robot chains traversing complex terrains \cite{Li2022}.

% In structured environments, sensor-fusion and learning-based methods have improved docking precision. YOLOv7-based detection, fused with LiDAR alignment, enabled robust industrial mobile robot recharging, achieving real-time recognition and sub-decimeter positioning in manufacturing settings \cite{Jia2023}. Regression-based monocular systems trained on LiDAR ground truth can influence ArUco marker distortions to estimate distance and orientation with centimeter-level accuracy, vastly outperforming SolvePnP methods while using only low-cost cameras \cite{Oh2025}.

% While these model-based and vision-driven controllers provide strong performance in defined scenarios, proximity missions in space docking, characterized by time-varying dynamics, unforeseen disturbances, and energy constraints, require more adaptive, data-driven control architectures. \ac{snn}s trained via the Reinforcement Learning (RL) paradigm can learn end‐to‐end docking policies from sensory inputs, offering fast inference, on‐chip adaptability, and robustness to unmodeled effects \cite{tang2021deep}.

% % Deep SNN

% RL paradigms in \ac{snn}s enable agents to learn control policies through trial-and-error interactions, a capability crucial for autonomous proximity operations in space docking. Bio-plausible learning rules, such as Spike-Timing-Dependent Plasticity (STDP) combined with reward signals, have been shown to approximate backpropagation and support multi-layer learning \cite{TavanaeiMaida2018BPSTDP, AnwaniRajendran2020NormAD, TaherkhaniBelatreche2018BPSL}. By incorporating eligibility traces and global reward feedback, these methods allow \ac{snn}s to adjust synaptic weights in response to docking success metrics, facilitating rapid adaptation to new docking trajectories.

% Scaling RL-trained \ac{snn} architectures to deep networks requires addressing vanishing spike activity and ensuring information propagation across layers. Techniques such as Spike Activation Lift Training (SALT) and Switched-BN enhance spike throughput in very deep \ac{snn}s, improving learning capacity under RL-like reward cues \cite{KimPanda2021SALT}. Likewise, weighted spikes encode multi-bit information per event, reducing decision latency, an essential factor for timely thruster commands during docking \cite{KimHuh2018Weighted}. These advances pave the way for deep \ac{snn}s that learn complex docking maneuvers through RL while maintaining low energy consumption.

% Proximity missions impose strict hardware constraints on power, area, and latency. Neuromorphic signal‐processing systems that employ ternary spike encoding and quantized \ac{snn}s achieve substantial memory and energy savings, making on-board RL plausible \cite{WangZhang2025Ternary, LinYuan2020ReRAM}. In-memory ReRAM-based architectures with ternary deep \ac{snn}s further reduce data movement and support fast synaptic updates under RL protocols \cite{LinYuan2020ReRAM}. Such hardware platforms can host RL-trained \ac{snn} controllers directly on spacecraft avionics, offering robust, low-power autonomy.

% Accurate temporal and spatial precision is vital for docking proximity control. Fractional‐order STDP (FO‐STDP) enhances gradient descent in \ac{snn}s, improving convergence speed and accuracy in gesture‐like input scenarios analogous to docking sensor streams \cite{YangVoyles2025FOSTDGD}. Biologically plausible multi‐spike learning algorithms integrate synaptic delay training to fine‐tune event timing, enabling precise control of approach velocities and alignment \cite{TaherkhaniBelatreche2018BPSL}.

% Optimizing the training pipeline further accelerates RL convergence in \ac{snn}s. Parameter initialization based on neuronal response asymptotes prevents vanishing gradients, enabling deeper RL‐trained \ac{snn}s to learn docking policies from sparse reward signals \cite{DingZhang2025Init}. Modeling ANN‐\ac{snn} conversion residuals as additive noise yields low‐latency networks that maintain policy fidelity under time constraints \cite{HuangDing2025Residual}. Hybrid training methods that jointly optimize membrane leak, thresholds, and weights reduce inference timesteps to a few ms\cite{XuLi2021DIET}.

% These advances in RL‐trained \ac{snn}s, spanning learning rules, deep architectures, neuromorphic hardware, temporal precision, and training optimizations, provide a unified foundation for developing energy‐efficient, low‐latency controllers for space docking proximity missions. \ac{dvs} cameras can supply sparse, event‐driven input streams to these \ac{snn} controllers, further enhancing their responsiveness and energy efficiency in docking scenarios.

% % DVS 

% \ac{dvs}s offer a fundamentally different paradigm from conventional frame-based cameras by asynchronously encoding pixel-level brightness changes as a sparse stream of events, yielding microsecond-scale temporal resolution and minimal data redundancy. This event-driven operation allows \ac{dvs} to detect fast motions with latencies as low as 3 milliseconds, while consuming only a fraction of the power needed by CMOS imagers \cite{Lee2014RealTimeGesture,Seifozzakerini2018Hough}. The high dynamic range (up to 120 dB) of \ac{dvs} further enables reliable operation under extreme illumination variations without saturating the sensor \cite{Seifozzakerini2018Hough,Bichler2012Extraction}. These attributes are particularly advantageous for proximity operations in space docking, where rapid, energy-efficient sensing of relative motion is critical.

% \ac{snn}s naturally complement \ac{dvs} by processing event streams natively through time-encoded spikes, enabling highly efficient feature extraction and pattern recognition. Early work demonstrated that the STDP can robustly learn temporal correlations from raw \ac{dvs} data, extracting motion patterns such as vehicle trajectories with minimal synaptic complexity and high noise tolerance \cite{Bichler2012Extraction,Thiele2018EventBased}. Architectures with localized lateral inhibition have been shown to learn hierarchical features in a single pass, achieving an accuracy above 96\,\% with only one presentation of the data \cite{Thiele2018EventBased,Zhao2014Feedforward}.

% Recent advances have expanded \ac{dvs}–\ac{snn} systems to more complex applications relevant to autonomous navigation and control. For instance, deep convolutional \ac{snn}s trained with surrogate gradients achieve competitive object localization accuracy with up to 126× energy savings compared to ANNs \cite{Barchid2023Localization,Zanatta2023Directly}. In RL scenarios, directly-trained \ac{snn}s on neuromorphic accelerators have shown superior generalization for UAV obstacle avoidance, reaching goals 98\,\% of the time while consuming an order of magnitude less energy than CNN counterparts \cite{Zanatta2023Directly,Salt2019Parameter}. Event-based action recognition using novel benchmarks, such as \ac{dvs}-Gesture-Chain, highlights the inherent temporal processing advantages of \ac{snn}s, enabling feed-forward networks to perceive event sequences without recurrent connections \cite{VicenteSola2024SpikingAction,Zanatta2023Directly}.

% For space docking missions, precise detection of geometric features such as planar edges and circular apertures is essential for alignment and approach control. Event-based adaptations of the Hough Transform implemented in \ac{snn}s allow real-time line detection and 3D parameter estimation directly on \ac{dvs} outputs with no external memory or CPU, significantly reducing latency and power consumption \cite{Seifozzakerini2018Hough}. Self-supervised information bottleneck learning further enhances event-based optical flow estimation, improving robustness to noise and reducing energy usage by over 90\,\% compared to ANN methods \cite{Yang2024SelfSupervised}. These capabilities suggest that \ac{dvs}–\ac{snn} pipelines can provide the low-latency, low-power sensing and processing required for autonomous proximity operations in on-orbit docking scenarios.

% % _____________________________________________________________________________________________________________________________
% % \subsection{Federated Learning}

% Federated learning (\ac{fl}) provides a family of aggregation strategies that enable distributed agents to collaboratively train a global model while keeping their data local. Foundational approaches such as FedAvg~\cite{Ch_1_R26}, FedProx~\cite{Ch_1_R27}, Scaffold~\cite{Ch_1_R28}, FedNova~\cite{Ch_1_R29}, and MOON~\cite{Ch_1_R30} introduce different mechanisms—ranging from simple model averaging to proximal regularization, control variates, update normalization, and contrastive alignment—to improve convergence under heterogeneous data distributions and varying client participation. These methods form the classical backbone of FL research.

% Beyond these baseline strategies, numerous studies investigate how FL can be adapted to real-world conditions characterized by non-IID data, communication bottlenecks, and resource constraints. Works such as~\cite{Ch2_R40, Ch2_R41, Ch2_R42, Ch2_R43, Ch2_R44, Ch2_R45, Ch2_R46, Ch2_R47, Ch2_R50, Ch2_R51, Ch2_R52, Ch2_R53} examine selective model aggregation, cloud-assisted optimization, incentive mechanisms, wireless resource allocation, hierarchical aggregation, security challenges, and reinforcement learning–based collaboration, illustrating the broad and rapidly expanding ecosystem of FL techniques across edge, vehicular, and IoT systems.

% A smaller but growing line of research focuses specifically on applying FL to spiking neural networks. Due to the limited on-device data available to each neuromorphic or edge agent, cooperative training becomes essential. Studies such as~\cite{Ch_1_R2} and FL-SNN introduce online FL schemes in which SNNs use local feedback—rather than backpropagation—and exchange selective synaptic information through periodic global communication, achieving improved accuracy–communication trade-offs in distributed neuromorphic settings.

% Other neuromorphic-focused work highlights how \ac{fl} can support energy-efficient event-driven learning across heterogeneous devices. For example,~\cite{Ch_1_R4, Ch_1_R1} explore the joint challenges of wireless bandwidth constraints, battery limitations, and privacy requirements in distributed SNN training. These works demonstrate that federated neuromorphic learning~\cite{Ch_1_R9} can reduce communication load, preserve local data privacy, and maintain competitive accuracy across uneven data distributions, emphasizing its suitability for edge intelligence.

% These studies show that while FL offers a promising mechanism for multi-agent knowledge sharing, its integration with SNNs remains a relatively new research direction. Bridging neuromorphic learning rules with federated aggregation—especially under spiking dynamics, heterogeneous agents, and communication-limited environments—continues to be an open challenge and motivates the contributions developed in this thesis.

% % \ac{fl} aggregation methods form a cornerstone of how distributed models learn collectively while maintaining the privacy of local data. The seminal aggregation method in FL is FedAvg, or Federated Averaging. As introduced by McMahan et al.~\cite{Ch_1_R26}, FedAvg operates by averaging the weights of models updated locally by clients. This simple yet effective approach allows a global model to benefit from diverse local updates without sharing the data itself.

% % Addressing heterogeneity in client data distributions, the FedProx method~\cite{Ch_1_R27}, introduced by Li et al., modifies the local optimization process. FedProx introduces a proximal term which moderates the deviation of local updates from the global model, aiming to stabilize training across clients with non-IID data.

% % The Scaffold method~\cite{Ch_1_R28} deals with statistical heterogeneity and client drift, issues prevalent in scenarios where client data is not Independent and Identically Distributed (IID). Karimireddy et al. propose using control variates that correct the local updates toward the global objective, which helps in reducing variance in updates and aligning clients closer to the global model.

% % Introduced by Wang et al., the FedNova method~\cite{Ch_1_R29} employs a novel normalization mechanism in the aggregation process that adjusts based on the number of local updates performed by each client. This design accommodates the diversity in client update contributions, particularly beneficial in non-IID data scenarios.

% % The MOON method, or Model-contrastive Federated Learning, minimizes the contrastive loss between local and global models to maintain consistency across updates~\cite{Ch_1_R30}. By focusing on minimizing differences in model parameters using a similarity metric, MOON seeks to preserve the quality of the global model despite the diversity of local datasets.

% % Each of these methods represents an evolution in FL, introducing unique adjustments to the aggregation process to enhance convergence, reduce communication overhead, and improve robustness against adversarial clients and non-IID data conditions.

% % Building on the foundational principles of \ac{fl} methods detailed previously, we now turn our focus towards specialized neural network architectures that leverage these \ac{fl} strategies under unique operational constraints. A particularly interesting area is the utilization of \ac{snn}s, which offer a biologically inspired alternative to traditional Artificial Neural Networks (ANNs). SNNs are well-suited for on-device learning in edge computing scenarios due to their efficient energy consumption and capability for processing temporal information. However, the deployment of SNNs in such environments is not without challenges, primarily due to the limited data available on individual devices, which could significantly constrain the learning capabilities.

% % The limitations imposed by on-device training of \ac{snn}s, due to the constrained data availability on each device, is studied in \cite{Ch_1_R2}. Based on the results, the limitation can be mitigated through cooperative training utilizing \ac{fl}. An online FL-based learning rule, termed FL-SNN, for networked on-device SNNs is introduced. Through this scheme, local feedback signals are utilized within each SNN instead of backpropagation, and global feedback is facilitated through communication via a base station, showcasing the potential to significantly enhance training over isolated approaches by enabling a flexible compromise between communication load and accuracy through selective synaptic weight exchange.

% % A novel approach of selective model aggregation in \ac{fl} within the context of Vehicular EDGE Computing (VEC) is explored in \cite{Ch2_R40}. This approach focuses on the unique challenges posed by the diversity in image quality and computational capacity of vehicular clients for image classification. The approach, which selectively aggregates `fine' local DNN models based on an evaluation of local image quality and computation capability without compromising client privacy, employs two-dimensional contract theory for model selection due to the central server's unawareness of these local parameters. This methodology is shown to outperform conventional federated averaging in terms of accuracy and efficiency on the MNIST and BelgiumTSC datasets, also offering higher utility at the central server.

% % The paper by \cite{Ch2_R41} discusses a novel approach for fast global model aggregation in \ac{fl} via cloud computation, aiming to address the primary bottleneck of limited communication bandwidth in the aggregation of locally computed updates across devices with strict latency and privacy requirements, like drones and smart vehicles. This approach, employing a sparse and low-rank optimization problem solution through a Difference-of-Convex-functions algorithm for joint device selection and beamforming design, demonstrates significant algorithmic advantages and performance improvements in numerical results.

% % According to \cite{Ch2_R42}, \ac{fl} is suggested as a solution to the challenges faced in training machine learning models on IoT data due to constraints in network bandwidth, storage, and privacy. The focus is on how existing work has primarily centered on learning algorithms' convergence time, leaving issues like incentive mechanisms largely unexplored. A deep reinforcement learning-based incentive mechanism is proposed to motivate edge nodes towards model training contribution, with its efficiency validated through numerical experiments.

% % In \cite{Ch_1_R4}, the exploration of synergies between wireless communications and artificial intelligence, particularly the challenges of implementing ML models on battery-powered devices connected via bandwidth-constrained channels, is discussed. The paper highlights how \ac{fl} for distributed training of SNNs and the integration of neuromorphic sensing with SNNs can help overcome these challenges.

% % The research presented in \cite{Ch_1_R1} introduces a \ac{fl} method designed for training decentralized and privacy-preserving SNNs, focusing on the energy efficiency advantages of SNNs in \ac{fl} scenarios across energy-constrained devices. The method's effectiveness is experimentally validated through improved accuracy and energy efficiency in comparison to ANNs on CIFAR10 and CIFAR100 benchmarks.

% % A comprehensive study on deploying distributed learning over wireless edge networks, highlighting the challenges and emerging paradigms like \ac{fl} and distributed inference, is provided in \cite{Ch2_R43}. It presents an overview of communication techniques for efficient deployment and future research opportunities within wireless networks.

% % The effect of user selection and resource allocation on the convergence time and accuracy of \ac{fl} over wireless networks was investigated in \cite{Ch2_R44}. A probabilistic user selection scheme is proposed alongside the use of ANNs to estimate unselected users' local FL models, showing a reduction in convergence time and improvement in model accuracy through simulations.

% % Federated deep learning approaches for cybersecurity in IoT applications are reviewed and experimentally analyzed in \cite{Ch2_R45}. The article highlights the superiority of \ac{fl} in preserving IoT device data privacy and enhancing attack detection accuracy across various deep learning models.

% % The challenge of training \ac{fl} algorithms over wireless networks is studied in \cite{Ch2_R46}, where the impact of wireless factors on training quality and the optimization of learning, wireless resource allocation, and user selection to minimize FL loss function are discussed. Simulation results demonstrate the effectiveness of the proposed framework in improving identification accuracy.

% % In \cite{Ch2_R47}, an investigation is conducted into the allocation of energy-efficient transmission and computation resources for \ac{fl} over wireless communication networks. The model considered involves users training local FL models with their data and sending these to a base station (BS), which then aggregates these models and broadcasts the aggregated model back to the users. The optimization problem formulated aims to minimize total energy consumption under a latency constraint, with an iterative algorithm proposed that derives closed-form solutions for various parameters at every step. Initial feasible solutions are generated through a bisection-based algorithm aimed at minimizing completion time. It is shown through numerical results that energy consumption can be reduced by up to 59.5\% compared to conventional FL methods.

% % In \cite{Ch_1_R9}, a lead federated neuromorphic learning (LFNL) technique is proposed, designed as a decentralized, energy-efficient, brain-inspired computing method utilizing \ac{snn}s. This technique allows edge devices to collaboratively train a global model, preserving privacy and significantly reducing both data traffic and computational latency, with only a slight accuracy loss reported. The efficacy of LFNL in reducing energy consumption while maintaining competitive recognition accuracy, despite uneven dataset distribution, is demonstrated through experimental results.

% % The aggregation strategies in \ac{fl} through a comprehensive mathematical convergence analysis, leading to the derivation of novel aggregation algorithms that adapt model architecture by differentiating client contributions based on loss values, is presented in \cite{Ch2_R49}. This approach, which extends beyond theoretical assumptions to practical performance evaluations, is compared with the conventional FedAvg method across both IID and non-IID settings without additional hypotheses.

% % An edge-based backhaul (BH) selection technique aimed at improving traffic delivery by leveraging multiobjective feedback, utilizing advantage-actor-critic deep reinforcement learning methods, is introduced in \cite{Ch2_R50}. To enhance DRL training performance in large-scale IoT system deployments, \ac{fl} is applied, enabling collaboration among multiple edge devices. The effectiveness of this federated DRL approach in solving the BH selection problem is verified through extensive simulations.

% % In \cite{Ch2_R51}, a hierarchical trajectory planning method named HALOES, which employs deep reinforcement learning within a \ac{fl} scheme, is proposed for efficient, automatic parking in narrow spaces. This method combines high-level deep reinforcement learning with low-level optimization, improving planning time and model generalization capabilities while protecting data privacy during model parameter aggregation. Simulation results affirm HALOES's efficiency in various narrow-space parking scenarios.

% % The hierarchical \ac{fl} paradigm of HiFL is discussed in \cite{Ch2_R52}, which aims to mitigate communication overhead in FL systems by integrating synchronous client-edge and asynchronous edge-cloud model aggregations. An enhanced design, HiFlash, incorporates adaptive staleness control and a heterogeneity-aware client-edge association strategy through deep reinforcement learning, demonstrating improved system efficiency, communication reduction, and maintained model accuracy in experiments.

% % A survey on poisoning attacks and defense strategies in \ac{fl} from a privacy-preserving perspective, classifying and analyzing poisoning attacks and defense mechanisms, is provided in \cite{Ch2_R53}. The paper highlights the urgency of defending against poisoning attacks and suggests potential research directions for both attack and defense strategies, emphasizing the need for systematic reviews in this area.



\ac{snn}s have attracted increasing attention due to their ability to model neural dynamics using discrete spike events, closely reflecting biological information processing. Unlike conventional artificial neural networks, learning in \ac{snn}s is governed by the precise timing of neuronal spikes, making temporal dynamics a central element of computation and adaptation.

Among neuron models, the Izhikevich model provides a widely adopted compromise between biological realism and computational efficiency, enabling the simulation of diverse firing patterns with low computational cost \cite{izhikevich2003simple}. This balance makes it suitable for large-scale and real-time learning systems, particularly in control and robotics applications.

Learning in \ac{snn}s is predominantly driven by \ac{stdp}, a biologically observed mechanism in which synaptic strength is modulated according to the relative timing of pre- and post-synaptic spikes \cite{Ch2_R9}. \ac{stdp} provides a competitive Hebbian learning framework that enables synaptic specialization through temporal correlations. Extensions of \ac{stdp} incorporating neuromodulatory signals, such as dopamine, address the distal reward problem by linking delayed reward feedback to earlier spike events through eligibility traces \cite{Ch_1_R22}. Complementary biophysical studies further attribute \ac{stdp} dynamics to intracellular calcium-dependent mechanisms, suggesting a deeper physiological basis for synaptic modification \cite{Ch2_R6}.

The \ac{stdp} has been shown to support reinforcement learning behaviors in \ac{snn}s, enabling agents to learn from sparse and delayed feedback. Such learning rules have been applied successfully in decision-making tasks, including multi-agent reinforcement learning scenarios such as the Iterated Prisoner’s Dilemma, where \ac{snn}s demonstrate competitive or superior performance compared to conventional neural models \cite{Ch2_R4}. Similar advantages have been observed in dynamic environments, where \ac{snn}s outperform multilayer perceptrons due to their efficient temporal processing and rapid response to changing inputs \cite{Ch2_R2}.

To bridge the gap between biologically plausible learning and machine learning efficiency, several approaches approximate gradient-based optimization within \ac{snn}s. Methods such as BP-\ac{stdp}, SpikePropamine, and other differentiable plasticity frameworks enable multi-layer learning by approximating backpropagation through spike timing and synaptic dynamics \cite{Ch2_R16, Ch2_R25}. Hierarchical Bayesian inference and probabilistic formulations further extend \ac{snn}s to structured learning tasks such as pattern recognition and uncertainty-aware inference \cite{Ch2_R14}. Transfer learning and parameter optimization techniques improve scalability and generalization, enabling \ac{snn}s to be applied to complex control and perception problems \cite{Ch2_R22, Salt2019Parameter, Ch2_R24}.

In robotics and autonomous systems, \ac{snn}s have been applied to real-time control tasks, including autonomous navigation, obstacle avoidance, and multi-task learning. Modified integrate-and-fire models combined with \ac{stdp}-based learning rules enable mobile robots to adapt across tasks such as target tracking and collision avoidance \cite{Ch2_R20}. Hybrid architectures that integrate \ac{snn}s with convolutional neural networks further enhance learning efficiency in high-dimensional sensory spaces, particularly under sparse reward conditions \cite{Ch2_R21}. These studies highlight the suitability of \ac{snn}s for adaptive control in environments characterized by uncertainty and limited computational resources.

Multi-agent systems (MAS) play a critical role in cooperative tasks such as formation control and docking, particularly in aerospace applications. Event-triggered consensus mechanisms have been widely studied to achieve coordination while reducing communication overhead, including impulsive control strategies for rapid convergence \cite{tan2019consensus}, dynamic event-triggered schemes to prevent Zeno behavior \cite{du2020dynamic}, and fixed-time consensus methods ensuring convergence within predefined time bounds \cite{liu2020fixedtime}. Neural-network-based adaptive controllers and deep reinforcement learning frameworks further enhance coordination under nonlinear dynamics and uncertainty \cite{cao2024event, zhang2020eventtriggered, nguyen2020deep}. Robust docking control under constraints such as sensor faults, input saturation, and strict timing has been addressed through barrier Lyapunov methods and prescribed-time control strategies \cite{liu2021event, wang2019prescribed}.

Vision-based docking has been demonstrated across marine, aerial, and space domains. Monocular and marker-based systems enable precise relative pose estimation for underwater and aerial docking using lightweight sensors \cite{Trslic2020, Figueiredo2020}. In spacecraft applications, adaptive controllers enforcing time-varying state constraints ensure safe docking under unknown payload dynamics \cite{Sankaranarayanan2025}. Cooperative docking using potential-field guidance and geometric control has been validated in multi-UAV and VTOL platforms \cite{Nikhilraj2025, Narvaez2021}. Modular and heterogeneous robot teams further extend docking capabilities through layered control architectures and self-assembling mechanisms \cite{Lashkari2020, Li2022}. While these approaches demonstrate high precision in structured scenarios, they rely heavily on model-based design and are less adaptable to unmodeled disturbances.

Event-based vision sensors, such as \ac{dvs}, provide an alternative sensing paradigm by asynchronously encoding brightness changes as sparse events. This enables microsecond-scale temporal resolution, high dynamic range, and significant reductions in power consumption compared to frame-based cameras \cite{Lee2014RealTimeGesture, Seifozzakerini2018Hough, Bichler2012Extraction}. These properties are particularly advantageous for proximity operations and docking tasks, where rapid response and energy efficiency are critical.

\ac{snn}s naturally complement \ac{dvs} by processing event streams directly through spike-based computation. \ac{stdp}-based learning has been shown to extract motion features and temporal correlations from raw \ac{dvs} data with high noise robustness \cite{Bichler2012Extraction, Thiele2018EventBased}. Hierarchical \ac{snn} architectures with lateral inhibition learn complex spatiotemporal features in a single pass, achieving high accuracy with minimal training \cite{Zhao2014Feedforward}. Recent work extends these systems to deep architectures and reinforcement learning scenarios, demonstrating substantial energy savings and competitive performance in object localization and UAV navigation tasks \cite{Barchid2023Localization, Zanatta2023Directly, Salt2019Parameter}. Event-based geometric feature extraction and optical flow estimation further enable low-latency perception suitable for docking and alignment tasks \cite{Seifozzakerini2018Hough, Yang2024SelfSupervised}.

Reinforcement learning (RL) in \ac{snn}s enables agents to learn control policies through trial-and-error interactions, making it well suited for autonomous docking and proximity operations. The \ac{stdp} combined with eligibility traces supports end-to-end policy learning without backpropagation \cite{TavanaeiMaida2018BPSTDP, AnwaniRajendran2020NormAD, TaherkhaniBelatreche2018BPSL}. Scaling these methods to deep \ac{snn}s requires addressing challenges such as vanishing spike activity and information propagation. Techniques including Spike Activation Lift Training, weighted spike encoding, and optimized parameter initialization improve learning stability and reduce inference latency \cite{KimPanda2021SALT, KimHuh2018Weighted, DingZhang2025Init}. Neuromorphic hardware platforms further support energy-efficient deployment of deep \ac{snn}s for real-time control \cite{LinYuan2020ReRAM, WangZhang2025Ternary}.

Federated Learning (\ac{fl}) provides a distributed training paradigm that enables multiple agents to collaboratively learn a global model while keeping data local. Classical methods such as FedAvg, FedProx, Scaffold, FedNova, and MOON address challenges related to data heterogeneity and communication efficiency \cite{Ch_1_R26, Ch_1_R27, Ch_1_R28, Ch_1_R29, Ch_1_R30}. Extensions of \ac{fl} focus on selective aggregation, incentive mechanisms, hierarchical coordination, and reinforcement learning-based collaboration in edge and IoT environments \cite{Ch2_R40, Ch2_R41, Ch2_R42, Ch2_R43, Ch2_R44, Ch2_R45, Ch2_R46, Ch2_R47, Ch2_R50, Ch2_R51, Ch2_R52, Ch2_R53}.

Applying \ac{fl} to \ac{snn}s introduces additional challenges due to spike-based dynamics and limited on-device data. Recent studies propose online and asynchronous federated schemes for \ac{snn}s that exchange selective synaptic information rather than full gradient updates, achieving improved accuracy–communication trade-offs \cite{Ch_1_R2}. Other works address energy constraints, wireless bandwidth limitations, and privacy preservation in distributed neuromorphic learning \cite{Ch_1_R1, Ch_1_R4, Ch_1_R9}. These studies indicate that federated neuromorphic learning remains an emerging field, particularly for multi-agent systems operating under strict resource constraints.

Existing research demonstrates that \ac{snn}s, when combined with reward-modulated learning, event-based sensing, and federated aggregation, offer a promising foundation for adaptive, energy-efficient, and scalable control in multi-agent docking scenarios. However, integrating biologically plausible learning rules with stable weight regulation, asynchronous federated updates, and event-driven perception remains an open challenge. These limitations motivate the methods developed in this thesis.
