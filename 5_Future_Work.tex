\chapter{Proposed Investigations}

The integration of \ac{snn} with \ac{fl} presents a novel approach to multiagent reinforcement learning on the EDGE, promising to simultaneously enhance learning efficiency and data privacy. This approach, however, introduces several challenges and opportunities for further investigation. Future work will focus on four primary areas:

\begin{itemize}
    \item \textbf{Improving Stable Learning in SNNs:} Addressing the challenge of learning stability and synaptic weight control in \ac{snn}s during reinforcement learning, particularly in response to dynamic environmental rewards.
    \item \textbf{Managing Communication Overhead in FL:} Reducing communication overhead among agents while ensuring responsiveness to changes through adaptive communication strategies.
    \item \textbf{Heterogeneity of Spiking Neuron Models:} Exploring the implications of neural network heterogeneity in spiking neuron models on collective learning outcomes and system performance.
    \item \textbf{Resilience to Model Poisoning Attacks:} Investigating the system's vulnerability to model poisoning attacks during \ac{fl} and developing strategies to mitigate such risks.
\end{itemize}

\section{Improving Stable Learning in SNNs}

The stability of learning in \ac{snn} is a foundational aspect for their deployment in dynamic environments, necessitating precise adjustments of synaptic weights in response to probable changes in reward signals. In Chapter 4, the adaptation mechanisms essential for maintaining the learning processes' stability, emphasizing the equilibrium between synaptic plasticity and homeostasis, were investigated. This involved developing algorithms that dynamically adjust learning rates and decay rates based on reward functions. Furthermore, the complexities of incorporating these adaptive mechanisms within the \ac{fl} framework were addressed, ensuring that distributed \ac{snn}s can learn from decentralized data sources while adapting to environmental changes.

While this research marks substantial progress, it also highlights the emergence of nuanced challenges, particularly in understanding and enhancing swarm behavior in contexts where a leader's presence and dynamic obstacles coexist. Future work will study the effects of these dual factors on swarm dynamics, focusing on how a swarm can adeptly react to dynamic obstacles while following a leader and maintaining its formation.

\section{Managing Communication Overhead in FL}

Efficient communication among distributed agents is a cornerstone of \ac{fl}, particularly in EDGE computing environments where bandwidth and latency can be significant constraints. The need to reduce communication overhead without compromising the system's responsiveness to changes presents a unique challenge. Initially, strategies for improving information distribution during the training in \ac{fl} should be explored. This involves investigating adaptive communication frameworks that dynamically adjust the frequency of model exchange based on current learning conditions. Secondly, the impact of reduced communication on the learning process should be studied, ensuring that critical information necessary for model updates is not lost. This includes developing algorithms to identify the most impactful updates to transmit, reducing redundancy without sacrificing learning efficacy. These methods will enhance local computations and inferences to reduce communication burden while maintaining system coherence and performance.

In Chapter 4, an algorithm was developed for event-triggered aggregation of \ac{fl}, which addresses managing communication overhead by utilizing a threshold mechanism for model updates. For future work, we propose extending this model with an additional index or threshold to further improve the communication overhead, especially in scenarios with larger swarms of agents. For instance, if we have 100 agents and the current threshold criteria are met by 50 agents, this still results in a substantial number of models being sent to the central server. Introducing an extra index (or threshold) like information entropy for measuring the amount of data in each neural network model or peer-to-peer communication between agents could reduce the number of models sent while ensuring the global model's integrity and efficacy.

\section{Heterogeneity of Spiking Neuron Models on Server}

Incorporating diversity in the spiking neuron models within multiagent systems presents both challenges and opportunities for synchronizing learning processes and achieving consensus in shared tasks. The initial focus will delve into how this diversity impacts individual and collective learning performance. This includes an examination of variations in learning efficiency, behavioral responses, and adaptability to diverse tasks. Studies prove the benefits of this heterogeneity, revealing that various neuron models significantly improve task performance, particularly in tasks with complex temporal structures. Moreover, this diversity has been linked to enhanced generalization capabilities, especially when the learning parameters are tuned inaccurately \cite{Ch5_R1}. Insights from previous studies indicate that heterogeneity in neuronal and synaptic dynamics can diminish spiking activity while simultaneously enhancing system performance, suggesting a pathway to achieving spike-efficient learning that conserves energy without compromising on learning efficacy \cite{Ch5_R2}.

This study aims to assess network model diversity's influence on the multiagent framework's robustness and resilience, particularly within \ac{fl}. To address this challenge, the future investigation includes exploring three potential methodologies: Neuroevolution of Augmenting Topologies (NEAT) algorithm, Transfer Learning, and Evolutionary Algorithms such as Particle Swarm Optimization (PSO) and Genetic Algorithms (GA). Each of these methods offers unique advantages for the optimization of the global model. NEAT, for instance, can evolve and optimize network topologies and parameters to adapt to various tasks dynamically. Transfer Learning, on the other hand, allows for leveraging pre-learned behaviors and patterns across different but related tasks, facilitating quicker adaptation. Evolutionary algorithms can optimize the parameters of the global model during the model aggregation process to achieve a cohesive and high-performing system.

\section{Resilience to Model Poisoning Attacks}

Model poisoning attacks during \ac{fl} pose significant threats to the integrity and reliability of the learning process. The first step in addressing this challenge involves identifying vulnerabilities within the \ac{snn}-FL integration that could be exploited by such attacks. This will be followed by the development of detection mechanisms for identifying anomalous behavior or compromised nodes within the federated network. Techniques such as Differential Privacy (DP) and robust statistical methods, including multi-Krum, can be good candidates. For example, the DP algorithm introduces randomness into the neural network model during the learning process, ensuring that the contribution of individual updates does not significantly affect the aggregated model. This makes it difficult for attackers to have their poisoned updates significantly influence the model's behavior \cite{Ch5_R3}. On the other hand, multi-Krum selects the most reliable update from among the participants based on a distance metric that identifies updates likely to be benign and representative of the true model.

These investigations will pave the way for more resilient, efficient, and adaptive multiagent systems capable of leveraging the strengths of both \ac{snn}s and \ac{fl} in dynamic and potentially adversarial environments.

