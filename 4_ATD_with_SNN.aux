\relax 
\citation{Ch5_ATD4}
\citation{Ch5_ATD4-5}
\citation{Ch5_ATD6}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Modular Learning in SNNs for optimal Multi-Agent Decision-Making}{34}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Ch5_ATD6}
\citation{Ch5_ATD7}
\citation{Ch5_STDP2}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The ATD problem and SNN-based solution}{35}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Learning using R-STDP}{35}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Active target defense game with three agents (LOS angles are shown for both agents).}}{36}{}\protected@file@percent }
\newlabel{fig:my_label4}{{4.1}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Two SNNs simultaneously play and control the invader and defender. Each agent uses the LOS angle and relative velocities for training.}}{36}{}\protected@file@percent }
\newlabel{fig:my_label2}{{4.2}{36}}
\citation{Ch5_STDP1}
\newlabel{Eq.14}{{4.1}{37}}
\newlabel{Eq.15}{{4.2}{37}}
\newlabel{Eq.16}{{4.3}{37}}
\citation{Ch5_STDP2}
\newlabel{Eq.17}{{4.4}{38}}
\newlabel{Eq.18}{{4.5}{38}}
\newlabel{Eq.19}{{4.6}{38}}
\newlabel{Eq.20}{{4.7}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Relative velocities and LOS angles used in the reward function}}{39}{}\protected@file@percent }
\newlabel{fig:my_label5}{{4.3}{39}}
\newlabel{Eq.21}{{4.8}{39}}
\newlabel{Eq.22}{{4.9}{39}}
\newlabel{Eq.23}{{4.10}{39}}
\citation{Ch5_SNNModel1}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Network structure and encoding method}{40}{}\protected@file@percent }
\newlabel{Eq.25}{{4.3}{40}}
\newlabel{Eq.25-1}{{4.11}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Network structure and encoding process for the input layer (Defender). Each neuron is associated with a membership function in GRF. The GRF encodes an input State ($S^t$) at each time step. There is both a training phase when ($\alpha = 0$) and an operating phase when ($\alpha = 1)$.}}{41}{}\protected@file@percent }
\newlabel{fig:my_label1}{{4.4}{41}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Weight training algorithm}}{42}{}\protected@file@percent }
\newlabel{Algorithm4.1}{{2}{42}}
\newlabel{Eq.26}{{4.12}{43}}
\citation{Ch5_R1}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Parameter values for LIF neuron model \cite  {Ch5_R1}}}{44}{}\protected@file@percent }
\newlabel{Table4.1}{{4.1}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Parameter values for \ac {stdp}}}{44}{}\protected@file@percent }
\newlabel{Table4.2}{{4.2}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Results}{44}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces \ac {snn}'s performance during training. Hollow circles show the initial positions.}}{45}{}\protected@file@percent }
\newlabel{fig:my_label6}{{4.5}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Changes in synaptic weights during training. Only Maximum synaptic weights for both agents are shown.}}{46}{}\protected@file@percent }
\newlabel{fig:my_label11}{{4.6}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces An illustration of input current to \ac {snn} and synaptic current to the output neurons after training for a single connection.}}{48}{}\protected@file@percent }
\newlabel{fig:my_label8}{{4.7}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Reward, eligibility trace, and weight change during the simulation for $W^{3-3}$. The $C(t) R(t)$ changes the synaptic weight by considering activation strength and reward value.}}{48}{}\protected@file@percent }
\newlabel{fig:my_label9}{{4.8}{48}}
\citation{Ch5_ATD6}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces \ac {snn}'s performance after training. The highlighted region shows the defender's dominant region. The purple dot is the optimal capture point.}}{49}{}\protected@file@percent }
\newlabel{fig:my_label7}{{4.9}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Simulation without noise}{49}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Simulation with noise}{50}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusion}{50}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces \ac {snn}'s performance in noisy conditions. A white Gaussian noise with a variance of 0.01 is added to the measured inputs.}}{51}{}\protected@file@percent }
\newlabel{fig:my_label12}{{4.10}{51}}
\@setckpt{4_ATD_with_SNN}{
\setcounter{page}{53}
\setcounter{equation}{12}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{5}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{2}
\setcounter{Maxaffil}{2}
\setcounter{authors}{0}
\setcounter{affil}{0}
\setcounter{r@tfl@t}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{35}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{nlinenum}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{60}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blind@countparstart}{0}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{blind@randomcount}{0}
\setcounter{blind@randommax}{0}
\setcounter{blind@pangramcount}{0}
\setcounter{blind@pangrammax}{0}
}
