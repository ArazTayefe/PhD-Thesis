\chapter*{Abstract}

This thesis presents a comprehensive study of multiagent reinforcement learning using Spiking Neural Networks (SNNs) for decentralized control in edge computing environments. Chapter 1 introduces the motivation and literature review, highlighting the need for biologically inspired neural models to achieve robust, energy-efficient learning in dynamic multiagent systems. Chapter 2 develops adaptive mechanisms for SNNs, focusing on stabilizing learning under sparse for optimal problems, and balancing synaptic plasticity with network equilibrium.

Chapter 3 explores federated learning as a lightweight strategy for sharing matured SNN policies among agents, aiming to reduce communication overhead while maintaining decentralized autonomy. The chapter demonstrates that event-triggered policy exchanges can improve efficiency without requiring full synchronization or centralized orchestration.

Chapter 4 delivers the main simulation results, introducing a vision-based multiagent docking framework that combines Dynamic Vision Sensor (DVS) event streams, adaptive light modulation, and deep SNN controllers. The proposed system enables a swarm of agents to cooperatively dock a 14,000 kg payload within 99 seconds, meeting IDSS soft-capture standards (lateral misalignment < 0.1 m, relative lateral rate < 0.04 m/s) and maintaining formation stability despite thruster minimum-impulse-bit constraints.

By integrating adaptive SNN learning, efficient policy sharing, and event-driven control, this research advances the development of resilient, responsive, and scalable multiagent systems for edge computing. The results demonstrate that neuromorphic approaches can deliver robust autonomy in complex, real-world cooperative tasks.

