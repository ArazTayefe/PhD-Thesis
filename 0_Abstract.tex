\chapter*{Abstract}

This thesis presents a comprehensive study of multiagent reinforcement learning using Spiking Neural Networks (SNNs) for decentralized control in edge computing environments. Chapter 1 introduces the motivation and literature review, highlighting the need for biologically inspired neural models to achieve robust, energy-efficient learning in dynamic multiagent systems. Chapter 2 develops adaptive mechanisms for SNNs, focusing on stabilizing learning under sparse for optimal problems, and balancing synaptic plasticity with network equilibrium.

Chapter 3 explores federated learning as a lightweight strategy for sharing matured SNN policies among agents, aiming to reduce communication overhead while maintaining decentralized autonomy. The chapter demonstrates that event-triggered policy exchanges can improve efficiency without requiring full synchronization or centralized orchestration.

Chapter 4 delivers the main simulation results, introducing a vision-based multiagent docking framework that combines Dynamic Vision Sensor (DVS) event streams, adaptive light modulation, and deep SNN controllers. The proposed system demonstrates robust cooperative docking, precise formation control, and resilience to actuation constraints, validating the effectiveness of neuromorphic approaches for complex multiagent coordination tasks.

By integrating adaptive SNN learning, efficient policy sharing, and event-driven control, this research advances the development of resilient, responsive, and scalable multiagent systems for edge computing. The results demonstrate that neuromorphic approaches can deliver robust autonomy in complex, real-world cooperative tasks.

