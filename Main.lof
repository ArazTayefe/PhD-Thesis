\acswitchoff 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Simple model of a \ac {snn}. The spike pattern shows that the neurons spike whenever the voltage of the neuron reaches a threshold.}}{3}{figure.1.1}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Active target defense game with three agents (LOS angles are shown for both agents).}}{16}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Two \ac {snn}s simultaneously play and control the invader and defender. Each agent uses the LOS angle and relative velocities for training.}}{16}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces An illustration of input current to \ac {snn} and synaptic current to the output neurons after training for a single connection.}}{17}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Relative velocities and LOS angles used in the reward function}}{20}{figure.2.4}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Network structure and encoding process for the input layer (Defender). Each neuron is associated with a membership function in \ac {grf}. The \ac {grf} encodes an input State ($S^t$) at each time step. There is both a training phase when ($\xi = 0$) and an operating phase when ($\xi = 1)$. The ``F2S Conversion" block converts fuzzy membership values to currents for the neurons according to \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {Eq.25-1}\unskip \@@italiccorr )}}.}}{23}{figure.2.5}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Reward, eligibility trace, and weight change during the simulation for $W^{3-3}$. The $C(t) R(t)$ changes the synaptic weight by considering activation strength and reward value.}}{24}{figure.2.6}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces \ac {snn}'s performance during training. Hollow circles show the initial positions.}}{28}{figure.2.7}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Changes in synaptic weights during training. Only Maximum synaptic weights for both agents are shown.}}{29}{figure.2.8}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces \ac {snn}'s performance after training. The highlighted region shows the defender's dominant region. The purple dot is the optimal capture point. The CO Type-E shows the reachable regions of the Invader and the Defender.}}{31}{figure.2.9}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces \ac {snn}'s performance in noisy conditions. A white Gaussian noise with a variance of 0.01 is added to the measured inputs.}}{33}{figure.2.10}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces The central server (the leader) and the surrounding follower agents (white drones). The follower agents learn to fly in a formation to maintain the commanded distance. The Local models trained individually by follower agents are sent to the leader. The leader aggregates the models and sends back the global model for another round of training of the follower agents.}}{36}{figure.3.1}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces \ac {snn} structure with encoding and decoding layers. Each input sub-layer consists of a fuzzy encoder followed by the fuzzy-to-spiking current conversion defined in \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {Eq.NS.3}\unskip \@@italiccorr )}}. During the training phase, the output layer receives input only from the random action selector, which is replaced by synaptic weight inputs during the testing phase.}}{39}{figure.3.2}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The fuzzy encoding principle for the input sub-layer.}}{40}{figure.3.3}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Synaptic weight change for $\lambda =5, \Psi ^{\mathcal {S}}=15.5$,\\ and $\mathcal {A}\mathcal { R}_{max}^G=1$.}}{52}{figure.3.4}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Reward-based learning rate and decay rate functions. In the blue region (active learning rate), the reward adjusts the weights, and in the red region (active decay rate), the RCSE method controls synaptic growth.}}{52}{figure.3.5}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces RCSE working principle in inhibiting the adjacent synaptic connections. The heatmap shows the synaptic weight matrix. Neurons have different firing strengths due to the difference in fuzzy membership values, which affects the increase or decrease rate and shapes the patterns in the synaptic weight matrix.}}{53}{figure.3.6}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Measured distances used for evaluating swarm flight performance and collision detection.}}{63}{figure.3.7}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Agents' trajectory during the test phase}}{63}{figure.3.8}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Variation of distances within the swarm during the test phase}}{64}{figure.3.9}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Adaptive response to commanded distance adjustments - reconfiguration during the test phase}}{64}{figure.3.10}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Trajectory adaptations of following agents in response to reward change for the leader during the test phase.}}{66}{figure.3.11}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Variations in distances after reward changes and Leader becomes Obstacle - test phase.}}{66}{figure.3.12}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Synaptic Weights before Reward change in \ac {RCSE} method.}}{68}{figure.3.13}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Synaptic Weights after Reward change in \ac {RCSE} method.}}{68}{figure.3.14}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Synaptic Weights before Reward change in Multiplicative Synaptic Normalization method.}}{68}{figure.3.15}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Synaptic Weights after Reward change in Multiplicative Synaptic Normalization method.}}{68}{figure.3.16}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Synaptic weights increase after reward change in \ac {RCSE} method.}}{70}{figure.3.17}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Synaptic weights decrease after reward change in \ac {RCSE} method.}}{70}{figure.3.18}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces Distances during the test phase before reward change in the proposed event-triggered \ac {fl} method.}}{71}{figure.3.19}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Distances during the test phase after reward change in the proposed event-triggered \ac {fl} method.}}{71}{figure.3.20}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces Frobenius norm of the Agent 1's weighs during the learning phase. The reward changes for the Leader after 600 s.}}{72}{figure.3.21}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces Communication times for agents and the Central Server (Leader). Red and blue dots show the times that agents and the Central Server have sent their model, respectively.}}{72}{figure.3.22}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces 3D schematic of the multi-agent docking mission environment. Multiple agents work collaboratively to push a central payload towards a \ac {scs} for docking alignment.}}{79}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces 2D representation of robots performing docking mission. Each agent pushes the payload towards the \ac {scs} to align them together. The \ac {scs} and agents are equipped with a \ac {dvs} that streams high-frequency data for the proximity mission.}}{80}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Deep \ac {snn} architecture with entropy-based adaptive pooling, multi-repository hidden layers, and biologically-inspired inhibitory and excitatory synapses. Purple, red, and blue arrows denote excitatory and yellow arrows denote inhibitory pathways.}}{88}{figure.4.3}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Structured First Hidden Layer Architecture with payload, and Agent Perception Repositories for Visual Perception.}}{92}{figure.4.4}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Structured Second Hidden Layer architecture showing the Rendezvous Phase Repository, Docking Phase Repository, Rendezvous Phase Inhibitor, and Docking Phase Inhibitor repositories interconnected through inhibitory (yellow) and excitatory (purple) synapses. External stimulation from contact sensors triggers mission-phase transitions.}}{95}{figure.4.5}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Output Layer Architecture with Lateral Inhibition between Opposing Direction Neurons to Enforce Winner-Take-All Dynamics within Each Control Axis.}}{97}{figure.4.6}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Computation of the activity matrix (\(A\)) from the time-averaged spiking activity.}}{100}{figure.4.7}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Input layer activity (\(\mathbf {A}^{\text {input}}\)), Payload Attention Activity (\(\mathbf {A}^{\text {H1}}_{pay}\)), and Neighboring Agent Attention Repository (\(\mathbf {A}^{\text {H1}}_{agt}\)) computation pipeline when the agent's \ac {alm} is turned off and most of the events are generated by the payload because of its larger weight in comparison with the agent. This feature puts more attention on the payload position.}}{102}{figure.4.8}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Computation of the Attention Mechanism for Reward Generation in the First Hidden Layer. The attention map (\(\mathcal {A}^{\text {Attention}}\)) is computed by comparing the input layer activity (\(\mathbf {A}^{\text {input}}\)) with the spatial positions of the first hidden layer neurons using a Gaussian-weighted mapping. The resulting attention map is then used to calculate the reward signal (\(r^{\text {H1}}\)) for each neuron in the first hidden layer by comparing it with the hidden layer activity (\(\mathbf {A}^{\text {H1}}\)).}}{103}{figure.4.9}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Reward function pipeline for the payload. The pipeline illustrates the raw \ac {dvs} events, the attention-based map, the normalized hidden layer activity during the initial training phase, and the reward signal calculated as the difference between the attention map and the hidden layer activity (\(r^{\text {H1}}(q)\)).}}{104}{figure.4.10}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Raw \ac {dvs} Events of the payload (Agent or \ac {scs} view)}}}{104}{figure.4.10}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Attention Map (\(\mathcal {A}^{\text {Attention}}\))}}}{104}{figure.4.10}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {First Hidden Layer Activity (\(\mathbf {A}^{\text {H1}}\))}}}{104}{figure.4.10}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {First Hidden Layer Reward (\(r^{\text {H1}}\))}}}{104}{figure.4.10}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Reward function pipeline for the agents. This pipeline demonstrates the raw \ac {dvs} events for multiple agents, the attention map, the hidden layer’s normalized activity, and the modulation signal computed for reward.}}{105}{figure.4.11}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Raw \ac {dvs} Events of the agents (Agent or \ac {scs} view)}}}{105}{figure.4.11}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Attention Map (\(\mathcal {A}^{\text {Attention}}\))}}}{105}{figure.4.11}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {First Hidden Layer Activity (\(\mathbf {A}^{\text {H1}}\))}}}{105}{figure.4.11}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {First Hidden Layer Reward (\(r^{\text {H1}}\))}}}{105}{figure.4.11}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Numerical example setup for Gaussian attention computation in the first hidden layer. (a) shows the input layer activity matrix representing time-averaged firing rates from the input layer \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:inputActivityMatrix}\unskip \@@italiccorr )}}. (b) illustrates the spatial arrangement of hidden-layer neurons, each serving as a query point $q(2,2)$ for attention calculation.}}{107}{figure.4.12}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Input layer activity matrix $\mathbf {A}^{\text {input}}$ (shown above) for numerical example of Gaussian attention computation.}}}{107}{figure.4.12}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Hidden-layer centers of attention (queries) for numerical example of Gaussian attention computation.}}}{107}{figure.4.12}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Attention weight computation for hidden neuron \( q = (2,2) \) at position \( (x_q, y_q) = (-0.333, -0.333) \). (a) shows the Gaussian weight map \( \gamma _{q} \) centered at the hidden neuron’s location. (b) illustrates the element-wise product of the weight map with the input layer activity matrix, highlighting the contributions to the attention calculation.}}{110}{figure.4.13}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Gaussian weight map $(\gamma _{q})$.}}}{110}{figure.4.13}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Weighted input layer activity $(\gamma _{q} \odot \mathbf {A}^{\text {input}})$.}}}{110}{figure.4.13}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces The DVS event image is masked by the upsampled binary detection mask derived from the first hidden layer’s output, isolating events corresponding to the active object (payload or agent).}}{116}{figure.4.14}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Oscillatory behavior of the Gaussian envelope used for computing the motion direction signal \(\mathcal {H}\) in the second hidden layer. The amplitude alternates between positive and negative values, shifting focus between the payload and agents based on the active \ac {alm}.}}{118}{figure.4.15}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Payload motion direction detection using a 2D Gaussian reward function with higher standard deviation.}}{118}{figure.4.16}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Payload approaching the center results in positive \(\mathcal {H}\) value based on the 2D Gaussian function with higher standard deviation.}}}{118}{figure.4.16}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Payload moving away from the center results in negative \(\mathcal {H}\) value based on the 2D Gaussian function with higher standard deviation.}}}{118}{figure.4.16}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces Neighboring agent motion direction detection using a 2D Gaussian reward function with lower standard deviation.}}{119}{figure.4.17}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Neighboring agent approaching the center results in negative \(\mathcal {H}\) value based on the 2D Gaussian function with lower standard deviation.}}}{119}{figure.4.17}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Neighboring agent moving away from the center results in positive \(\mathcal {H}\) value based on the 2D Gaussian function with lower standard deviation.}}}{119}{figure.4.17}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces The oscillatory Gaussian envelope used to compute the motion direction signal $\mathcal {H}$ for reward modulation in the second hidden layer. The center can be \ac {scs} or the agent's \ac {dvs} center.}}{120}{figure.4.18}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The oscillatory Gaussian envelope when the \ac {alm} is off (payload's moves away from the center results in negative values).}}}{120}{figure.4.18}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The oscillatory Gaussian envelope when the agent \ac {alm} is on (Agent's moves away from the center results in positive values).}}}{120}{figure.4.18}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Velocity-aligned activity template \(\mathbf {M}\) (left) and opposite-direction template \(\setbox \z@ \hbox {\mathsurround \z@ $\textstyle \mathbf {M}$}\mathaccent "0365{\mathbf {M}}\) (right) for an agent moving with heading \(\varphi = \pi /4\) and normalized speed \(\bar {\mathcal {V}} = 0.6\).}}{122}{figure.4.19}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{122}{figure.4.19}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{122}{figure.4.19}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces Output layer reward computation based on directional error between commanded and executed motion.}}{129}{figure.4.20}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Second hidden layer: population vector decoding}}}{129}{figure.4.20}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Commanded vs executed direction (reward routing)}}}{129}{figure.4.20}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces Schematic of the per-layer R-STDP weight update. The eligibility trace is calculated based on the firing rate of the neurons in layer \(\ell \) and \(\ell +1\). The per-neuron reward (\(r_q\)) is computed based on the layer-specific reward functions. The weight update is obtained by multiplying the eligibility trace by the per-neuron reward.}}{131}{figure.4.21}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces High-level architecture of the spiking neural network for multi-agent docking. The network processes DVS input through attention and phase repositories to generate thrust commands for docking maneuvers.}}{134}{figure.4.22}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces Effect of the \ac {alm} on visual perception. The ALM significantly enhances the visibility of proximal agents in the DVS input, improving the network's ability to detect and differentiate them from the payload.}}{136}{figure.4.23}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Simulation of the environment with Agents' \ac {alm} turned off, showing baseline brightness distribution.}}}{136}{figure.4.23}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Simulation of the environment with Agents' \ac {alm} turned on, illustrating enhanced visibility and separation of each agent.}}}{136}{figure.4.23}%
\contentsline {figure}{\numberline {4.24}{\ignorespaces Attention maps illustrating the effect of the \ac {alm} on visual focus. The \ac {alm} enables dynamic shifting of attention from the payload to the proximal agent by generating distinct DVS event patterns. Colorbar values indicate the normalized attention strength, where brighter regions correspond to locations receiving stronger attention.}}{137}{figure.4.24}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Attention map when the Agents' \ac {alm} is off, highlighting the detected payload position.}}}{137}{figure.4.24}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Attention map when the Agents' \ac {alm} is on, emphasizing the detected proximal agent’s position.}}}{137}{figure.4.24}%
\contentsline {figure}{\numberline {4.25}{\ignorespaces SNN structure in the first hidden layer under externally controlled attention signaling: (a) agents’ \ac {alm} disabled, which corresponds to the absence of ALM illumination and results in payload-focused visual processing; (b) agents’ \ac {alm} enabled, which corresponds to active ALM illumination and emphasizes proximal agent detection. Inactive neuron repositories and synaptic connections are depicted in gray, while dotted lines represent inactive inhibitory pathways.}}{138}{figure.4.25}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{138}{figure.4.25}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{138}{figure.4.25}%
\contentsline {figure}{\numberline {4.26}{\ignorespaces Detector repository activity during initial training with \ac {alm} off. The payload detector remains active, while the proximal agent detector is suppressed due to inhibitory signals from the payload attention Inhibitor.}}{139}{figure.4.26}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Activity of the payload detector repository during initial training phases with the Agents' \ac {alm} turned off.}}}{139}{figure.4.26}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Activity of the proximal agent detector repository during initial training phases with the Agents' \ac {alm} turned off.}}}{139}{figure.4.26}%
\contentsline {figure}{\numberline {4.27}{\ignorespaces Detector repository activity during initial training with \ac {alm} on. The proximal agent detector becomes active, while the payload detector is suppressed by ALM-induced inhibition.}}{140}{figure.4.27}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Activity of the payload detector repository during initial training phases with the Agents' \ac {alm} turned on.}}}{140}{figure.4.27}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Activity of the proximal agent detector repository during initial training phases with the Agents' \ac {alm} turned on.}}}{140}{figure.4.27}%
\contentsline {figure}{\numberline {4.28}{\ignorespaces Agent detector repository activity after learning convergence with \ac {alm} off. The payload detector shows strong, localized activity, while the proximal agent detector remains inactive.}}{141}{figure.4.28}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Activity of the payload detector repository after learning convergence with the Agents' \ac {alm} turned off.}}}{141}{figure.4.28}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Activity of the proximal agent detector repository after learning convergence with the Agents' \ac {alm} turned off.}}}{141}{figure.4.28}%
\contentsline {figure}{\numberline {4.29}{\ignorespaces Agent detector repository activity after learning convergence with \ac {alm} on. The proximal agent detector shows strong, localized activity, while the payload detector remains inactive.}}{142}{figure.4.29}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Activity of the payload detector repository after learning convergence with the Agents' \ac {alm} turned on.}}}{142}{figure.4.29}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Activity of the proximal agent detector repository after learning convergence with the Agents' \ac {alm} turned on.}}}{142}{figure.4.29}%
\contentsline {figure}{\numberline {4.30}{\ignorespaces Second hidden layer activity for the rendezvous and docking phases for Agent 1: (a) \ac {rpr} activity 135 degree that matches the LOS of the payload regarding the Agent 1 and (b) \ac {dpr} activity shows 45 degree LOS toward the docking point.}}{143}{figure.4.30}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Initial iterations of the rendezvous phase.}}}{143}{figure.4.30}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Initial iterations of the docking phase}}}{143}{figure.4.30}%
\contentsline {figure}{\numberline {4.31}{\ignorespaces Hidden layer 2 and output layer activity during the rendezvous phase.}}{144}{figure.4.31}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Commanded heading generated by the Hidden layer 2 activity during the rendezvous phase vs the actual agent's LOS regarding the payload.}}}{144}{figure.4.31}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Output layer activity during rendezvous phase}}}{144}{figure.4.31}%
\contentsline {figure}{\numberline {4.32}{\ignorespaces Hidden layer 2 and output layer activity during the docking phase.}}{145}{figure.4.32}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Hidden layer 2 activity during docking phase}}}{145}{figure.4.32}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Output layer activity during docking phase}}}{145}{figure.4.32}%
\contentsline {figure}{\numberline {4.33}{\ignorespaces Distances during time.}}{146}{figure.4.33}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Agent 1's distance from the payload during rendezvous phase}}}{146}{figure.4.33}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Payload's distance from the docking center}}}{146}{figure.4.33}%
\contentsline {figure}{\numberline {4.34}{\ignorespaces Reward profile during the docking phase}}{147}{figure.4.34}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Formation phase}}}{147}{figure.4.34}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Docking phase}}}{147}{figure.4.34}%
\contentsline {figure}{\numberline {4.35}{\ignorespaces Views during the rendezvous phase at different time steps. In the \ac {dvs} views, yellow regions represent the direction of motion as determined by event polarities, while white lines in (a) and (b) depict the trajectories of the payload and agents.}}{148}{figure.4.35}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {View From the \ac {scs} at 5 seconds}}}{148}{figure.4.35}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {DVS View From the \ac {scs} at 5 seconds}}}{148}{figure.4.35}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {View From the \ac {scs} at 15 seconds}}}{148}{figure.4.35}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {DVS View From the \ac {scs} at 15 seconds}}}{148}{figure.4.35}%
\contentsline {figure}{\numberline {4.36}{\ignorespaces Views during the docking phase at different time steps. In the \ac {dvs} views, yellow regions represent the direction of motion as determined by event polarities, while white lines in (a) and (b) depict the trajectories of the payload and agents.}}{149}{figure.4.36}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {View From the \ac {scs} at 30 seconds}}}{149}{figure.4.36}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {DVS View From the \ac {scs} at 30 seconds}}}{149}{figure.4.36}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {View From the \ac {scs} at 60 seconds}}}{149}{figure.4.36}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {DVS View From the \ac {scs} at 60 seconds}}}{149}{figure.4.36}%
\contentsline {figure}{\numberline {4.37}{\ignorespaces Views during the final approach and soft capture. In the \ac {dvs} views, yellow regions represent the direction of motion as determined by event polarities, while white lines in (a) and (b) depict the trajectories of the payload and agents.}}{151}{figure.4.37}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {View From the \ac {scs} at 99 seconds}}}{151}{figure.4.37}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {DVS View From the \ac {scs} at 99 seconds}}}{151}{figure.4.37}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {View From the \ac {scs} at docking completion}}}{151}{figure.4.37}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {DVS View From the \ac {scs} at docking completion}}}{151}{figure.4.37}%
\addvspace {10\p@ }
