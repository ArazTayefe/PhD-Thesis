\chapter{Literature review}

\section{Spiking Neural Network}

\ac{snn} and their learning algorithms have garnered significant attention for their potential to model complex neural dynamics and learning processes observed in biological systems. This literature review explores various facets of \ac{snn}s, focusing on their learning mechanisms, including STDP, and their applications in solving computational tasks that mirror biological learning behaviors.

The investigation of competitive Hebbian learning through STDP revealed how synaptic efficacy is modulated by the timing of spikes. This highlighted temporal dynamics' significance in synaptic modification and competitive learning within neural circuits \cite{Ch2_R9}.

In \cite{Ch_1_R22} the distal reward problem by linking STDP with dopamine signaling was tackled, illustrating a novel approach to reward-based learning in the brain. The study proposed a model in which dopamine modulated STDP mechanisms, effectively capturing the essence of reward-based learning processes.

Another research posited that STDP emerges from fundamental learning rules governed by intracellular calcium dynamics. This challenged the primacy of STDP, suggesting a deeper biophysical basis for synaptic strength regulation \cite{Ch2_R6}.

An examination of rate dynamics in LIF neurons with strong synapses focused on synaptic strength's influence on neural computation. Findings provided insights into synaptic integration and its effects on neurons' computational properties \cite{Ch2_R7}.

In \cite{Ch2_R5} an extensive review of the development and implications of STDP in neural circuits was provided. Their work highlighted the critical role of precise spike timing in synaptic modification, enriching our understanding of the neural basis for learning and memory .

A study on multiagent reinforcement learning within the Iterated Prisoner's Dilemma framework highlighted \ac{snn}s' comparable or enhanced performance against traditional models. This emphasized spike timing's critical role in complex decision-making \cite{Ch2_R4}.

The introduction of a model for parallel path planning using spiking neural activity was inspired by hippocampal navigation strategies. Through simulations, the model efficiently solved spatial navigation problems, showcasing the biologically plausible mechanisms of cognitive tasks within \ac{snn}s \cite{Ch2_R3}.

In a pioneering study, the implementation of probabilistic inference within LIF neuron networks was demonstrated, illustrating the transformation of Bayesian networks into a computable framework for \ac{snn}s. The methodology involved the adaptation of Bayesian networks to facilitate computation by \ac{snn}s, with findings highlighting \ac{snn}s' capability to perform complex cognitive functions through probabilistic reasoning \cite{Ch2_R1}.

The performance comparison between \ac{snn}s and multilayer perceptrons in a computer-based racing game showed \ac{snn}s' superior adaptability and decision-making capabilities in dynamic environments. This was attributed to the efficient processing of real-time data through spike-based mechanisms \cite{Ch2_R2}.


%% ------------------------------------------------------------

A spiking neural model aimed at adaptive arm control integrates structures and mechanisms from the motor cortex and cerebellum, mapped onto a simulated three-link arm. Utilizing a stability framework, it dynamically adapts to changes in arm dynamics and kinematic structure, such as growth or movement through different media \cite{Ch2_R10}. This model demonstrates the potential of \ac{snn}s in replicating complex motor control tasks, suggesting their applicability in both understanding biological systems and robotics.

Hierarchical Bayesian inference within \ac{snn}s introduces a learning algorithm based on synaptic plasticity, showcasing the ability of \ac{snn}s to execute complex tasks like pattern recognition through hierarchical structures \cite{Ch2_R14}. This emphasizes the adaptability and computational efficiency of \ac{snn}s.

A bio-inspired \ac{snn} framework for nonlinear system control focuses on UAV obstacle avoidance, employing a hierarchical learning approach through \ac{stdp} \cite{Ch2_R11}. This network effectively processes visual data for real-time control in robotics, showcasing the significance of \ac{snn}s in neuromorphic computing applications.

Generalized leaky integrate-and-fire (GLIF) models classify multiple neuron types by fitting these models to a diverse set of electrophysiological data \cite{Ch2_R12}. This work demonstrates the capability of simple neuron models to represent complex neural dynamics, providing tools for neural circuit studies.

First-spike-based visual categorization employs \ac{stdp} in \ac{snn}s, highlighting their efficiency in pattern recognition tasks by leveraging the temporal dynamics of spikes \cite{Ch2_R13}. This approach offers a promising method for neuromorphic hardware implementations.

Synaptic-dependent spike latency in \ac{snn}s for UAV control employs spiking activity simulations in response to environmental stimuli for efficient path planning \cite{Ch2_R15}. This study exemplifies \ac{snn} applications in navigation and control, highlighting their potential in real-time decision-making for autonomous systems.

BP-STDP, approximating backpropagation using spike timing-dependent plasticity, bridges the gap between \ac{snn} mechanisms and traditional neural network computational efficiency \cite{Ch2_R16}. This algorithm advances learning algorithms for \ac{snn}s, making them more accessible for machine learning tasks.

Indirect and direct training methods for \ac{snn}s in end-to-end control of a lane-keeping vehicle highlight the effectiveness of both approaches in utilizing \ac{snn}s for real-world control tasks, providing insights into training \ac{snn}s for complex systems like autonomous vehicles \cite{Ch2_R17}.

N3-CPL, a neuroplasticity-based learning method for neuromorphic networks, focuses on cell proliferation in \ac{snn}s, enhancing learning capabilities through mechanisms inspired by biological neural network growth and adaptation \cite{Ch2_R18}.

Parameter optimization in an \ac{snn} model for UAV obstacle avoidance tackles the challenge of tuning \ac{snn} parameters for specific tasks using optimization techniques, emphasizing the importance of optimization in \ac{snn} application for real-time processing and decision-making \cite{Ch2_R19}.

%% ------------------------------------------------------------

A methodology for multi-task autonomous learning in mobile robots using \ac{snn}s was proposed in \cite{Ch2_R20}. Modified Integrate-and-Fire and \ac{lif} neuron models were employed, alongside a task switch mechanism inspired by lateral inhibition and a novel learning rule based on \ac{stdp}. This approach demonstrated \ac{snn}s' capabilities in efficiently learning and adapting across various tasks such as obstacle avoidance and target tracking.

An autonomous learning framework that combines \ac{snn}s with a pre-trained binary Convolutional Neural Network for image-based reinforcement learning was developed in \cite{Ch2_R21}. This hybrid model efficiently processes high-dimensional sensory data and learns from sparse rewards, highlighting the synergistic potential of \ac{snn}s and CNNs in complex visual environments.

A transfer learning algorithm for \ac{snn}s aimed at deep learning tasks was introduced by \cite{Ch2_R22}, utilizing Centered Kernel Alignment for domain distance measurement and focusing on domain-invariant representation. This methodology enables effective knowledge transfer, showcasing the scalability and adaptability of \ac{snn}s.

The integration of \ac{snn}s within wireless communication systems, focusing on energy-efficient, distributed processing, was investigated in \cite{Ch_1_R4}. Through \ac{fl} and neuromorphic sensing, the potential for \ac{snn}s to enhance low-power edge intelligence and communication was demonstrated.

Mathematical constraints influencing Hebbian learning and STDP in \ac{snn}s were explored in \cite{Ch2_R24}. The analysis revealed relationships between synaptic weight promotion/demotion probabilities and normalized weights, offering insights into optimizing \ac{snn} training.

"Spikepropamine," incorporating differentiable plasticity within \ac{snn}s, was presented in \cite{Ch2_R25}. This approach enables adaptive learning and improved task performance, signifying advancements in neuromorphic computing and robotics applications of \ac{snn}s.

NeuronGPU, a library for simulating large-scale networks of spiking neurons with GPU acceleration, was developed in \cite{Ch2_R26}. This tool demonstrated scalability and efficiency in simulating complex neuronal dynamics, marking a significant contribution to computational neuroscience tools.

HybridSNN, an architecture blending shallow \ac{snn}s with machine learning techniques for adaptive deep learning, was proposed by \cite{Ch2_R27}. Through data-driven optimization and a novel network structure, the effectiveness of this architecture in complex pattern recognition tasks was showcased.

The integration of STDP learning with binary networks for image-based reinforcement learning was explored by \cite{Ch2_R28}. This methodology enabled efficient learning from high-dimensional inputs and sparse rewards, highlighting the utility of \ac{snn}s in reinforcement learning frameworks.

QC\_SANE, a robust DRL framework utilizing a quantile critic with a spiking actor and normalized ensemble, was introduced in \cite{Ch2_R29}. This approach significantly enhanced performance and robustness in continuous control problems, demonstrating the potential of \ac{snn}s in DRL applications.


%% ---------------------------------------------------------------

A novel biological-like controller utilizing enhanced \ac{snn}s aimed at emulating human arm control was introduced \cite{Ch2_R30}. The incorporation of a novel synapse model simulating biological synapses with multiple channels significantly enhances the realism of synaptic interactions. The model, through supervised STDP learning, effectively adapts and learns from dynamic changes, showcasing efficient control over arm movements.

Another study presented a control algorithm for multiagent cooperation using \ac{snn}s, leveraging the Izhikevich model of spiking neurons \cite{Ch2_R31}. The algorithm's capability for dynamic restructuring of the neural network in real-time facilitates adaptive cooperative behavior among agents. Through simulations, this control algorithm exhibited efficient cooperation, marking an advancement over traditional neural network approaches in dynamic environments.

The development of a brain-inspired approach for collision-free movement planning in small operational spaces using \ac{snn}s was also documented \cite{Ch2_R32}. By integrating the \ac{lif} neuron model with a dynamic learning mechanism, the \ac{snn} successfully simulates complex movement planning and adaptation, validating its applicability to tasks requiring precise control and collision avoidance.

Deep Spiking Q-Networks (DSQNs) were introduced for human-level control in reinforcement learning tasks, incorporating back-propagated error signals into an STDP-based learning framework \cite{Ch2_R33}. DSQNs achieve high performance on Atari game simulations, demonstrating the potential of directly trained \ac{snn}s for complex decision-making tasks.

Continuous learning in \ac{snn}s trained with local rules to mitigate catastrophic forgetting (CF) was explored, proposing architecture-based methods, memory replay, and regularization techniques \cite{Ch2_R34}. These methods effectively reduce CF, highlighting the potential of \ac{snn}s for continuous and adaptive learning.

Investigations into STDP with activation-dependent scaling for receptive field development in \ac{snn}s showcased the modified STDP rule's enhancement of the network's autonomous development of receptive fields \cite{Ch2_R35}. This improvement in classification accuracy on the MNIST dataset underscores the importance of adaptive learning rules in optimizing \ac{snn} performance for pattern recognition tasks.

A focus on sequence learning in \ac{snn}s modeled on hippocampal circuitry achieved learning in a single trial \cite{Ch2_R36}. The network architecture, inspired by the brain's hippocampal structure, demonstrates effective sequence learning capabilities, offering insights into how biological principles can enhance learning efficiency in neural networks.

A learning algorithm modulating STDP with back-propagated error signals for audio classification tasks was developed \cite{Ch2_R37}. This study demonstrates the feasibility of training \ac{snn}s for complex auditory pattern recognition, achieving competitive performance and marking a significant advancement in training \ac{snn}s for real-world applications.

Meta neurons were introduced to improve \ac{snn}s for efficient spatio-temporal learning \cite{Ch2_R38}. Incorporating second-order dynamics and a recovery variable into neuron models, the \ac{snn}s exhibit enhanced performance across various learning tasks, highlighting the potential of advanced neuron models in capturing complex patterns and improving \ac{snn}s' generalization ability.


\section{Federated Learning}

\ac{snn}s offer a promising alternative to conventional ANN for the implementation of on-device low-power online learning and inference. On-device training is, however, constrained by the limited amount of data available at each device.

The limitations imposed by on-device training of \ac{snn}s, due to the constrained data availability on each device, is studied in \cite{Ch_1_R2}. Based on the results, the limitation can be mitigated through cooperative training utilizing \ac{fl}. An online FL-based learning rule, termed FL-SNN, for networked on-device SNNs is introduced. Through this scheme, local feedback signals are utilized within each SNN instead of backpropagation, and global feedback is facilitated through communication via a base station, showcasing the potential to significantly enhance training over isolated approaches by enabling a flexible compromise between communication load and accuracy through selective synaptic weight exchange.

A novel approach of selective model aggregation in \ac{fl} within the context of Vehicular edge computing (VEC) is explored in \cite{Ch2_R40}. This approach focuses on the unique challenges posed by the diversity in image quality and computational capacity of vehicular clients for image classification. The approach, which selectively aggregates 'fine' local DNN models based on an evaluation of local image quality and computation capability without compromising client privacy, employs two-dimensional contract theory for model selection due to the central server's unawareness of these local parameters. This methodology is shown to outperform conventional federated averaging in terms of accuracy and efficiency on the MNIST and BelgiumTSC datasets, also offering higher utility at the central server.

The paper by \cite{Ch2_R41} discusses a novel approach for fast global model aggregation in \ac{fl} via over-the-air computation, aiming to address the primary bottleneck of limited communication bandwidth in the aggregation of locally computed updates across devices with strict latency and privacy requirements, like drones and smart vehicles. This approach, employing a sparse and low-rank optimization problem solution through a DC algorithm for joint device selection and beamforming design, demonstrates significant algorithmic advantages and performance improvements in numerical results.

According to \cite{Ch2_R42}, \ac{fl} is suggested as a solution to the challenges faced in training machine learning models on IoT data due to constraints in network bandwidth, storage, and privacy. The focus is on how existing work has primarily centered on learning algorithms' convergence time, leaving issues like incentive mechanisms largely unexplored. A deep reinforcement learning-based incentive mechanism is proposed to motivate edge nodes towards model training contribution, with its efficiency validated through numerical experiments.

In \cite{Ch_1_R4}, the exploration of synergies between wireless communications and artificial intelligence, particularly the challenges of implementing ML models on battery-powered devices connected via bandwidth-constrained channels, is discussed. The paper highlights how \ac{fl} for distributed training of SNNs and the integration of neuromorphic sensing with SNNs can help overcome these challenges.

The research presented in \cite{Ch_1_R1} introduces a \ac{fl} method designed for training decentralized and privacy-preserving SNNs, focusing on the energy efficiency advantages of SNNs in \ac{fl} scenarios across energy-constrained devices. The method's effectiveness is experimentally validated through improved accuracy and energy efficiency in comparison to ANNs on CIFAR10 and CIFAR100 benchmarks.

A comprehensive study on deploying distributed learning over wireless edge networks, highlighting the challenges and emerging paradigms like \ac{fl} and distributed inference, is provided in \cite{Ch2_R43}. It presents an overview of communication techniques for efficient deployment and future research opportunities within wireless networks.

The effect of user selection and resource allocation on the convergence time and accuracy of \ac{fl} over wireless networks was investigated in \cite{Ch2_R44}. A probabilistic user selection scheme is proposed, alongside the use of ANNs to estimate unselected users' local FL models, showing a reduction in convergence time and improvement in model accuracy through simulations.

Federated deep learning approaches for cybersecurity in IoT applications are reviewed and experimentally analyzed in \cite{Ch2_R45}. The article highlights the superiority of \ac{fl} in preserving IoT device data privacy and enhancing attack detection accuracy across various deep learning models.

The challenge of training \ac{fl} algorithms over wireless networks is studied in \cite{Ch2_R46}, where the impact of wireless factors on training quality and the optimization of learning, wireless resource allocation, and user selection to minimize FL loss function are discussed. Simulation results demonstrate the effectiveness of the proposed framework in improving identification accuracy.

In \cite{Ch2_R47}, an investigation is conducted into the allocation of energy-efficient transmission and computation resources for \ac{fl} over wireless communication networks. The model considered involves users training local FL models with their data and sending these to a base station (BS), which then aggregates these models and broadcasts the aggregated model back to the users. The optimization problem formulated aims to minimize total energy consumption under a latency constraint, with an iterative algorithm proposed that derives closed-form solutions for various parameters at every step. Initial feasible solutions are generated through a bisection-based algorithm, aimed at minimizing completion time. It is shown through numerical results that energy consumption can be reduced by up to 59.5\% compared to conventional FL methods.

In \cite{Ch_1_R9}, a lead federated neuromorphic learning (LFNL) technique is proposed, designed as a decentralized, energy-efficient, brain-inspired computing method utilizing \ac{snn}s. This technique allows edge devices to collaboratively train a global model, preserving privacy and significantly reducing both data traffic and computational latency, with only a slight accuracy loss reported. The efficacy of LFNL in reducing energy consumption while maintaining competitive recognition accuracy, despite uneven dataset distribution, is demonstrated through experimental results.

The aggregation strategies in \ac{fl} through a comprehensive mathematical convergence analysis, leading to the derivation of novel aggregation algorithms that adapt model architecture by differentiating client contributions based on loss values, is presented in \cite{Ch2_R49}. This approach, which extends beyond theoretical assumptions to practical performance evaluations, is compared with the conventional FedAvg method across both IID and Non-IID settings without additional hypotheses.

An edge-based backhaul (BH) selection technique aimed at improving traffic delivery by leveraging multiobjective feedback, utilizing advantage-actor-critic deep reinforcement learning methods, is introduced in \cite{Ch2_R50}. To enhance DRL training performance in large-scale IoT system deployments, \ac{fl} is applied, enabling collaboration among multiple edge devices. The effectiveness of this federated DRL approach in solving the BH selection problem is verified through extensive simulations.

In \cite{Ch2_R51}, a hierarchical trajectory planning method named HALOES, which employs deep reinforcement learning within a \ac{fl} scheme, is proposed for efficient, automatic parking in narrow spaces. This method combines high-level deep reinforcement learning with low-level optimization, improving planning time and model generalization capabilities while protecting data privacy during model parameter aggregation. Simulation results affirm HALOES's efficiency in various narrow space parking scenarios.

The hierarchical \ac{fl} paradigm of HiFL is discussed in \cite{Ch2_R52}, which aims to mitigate communication overhead in FL systems by integrating synchronous client-edge and asynchronous edge-cloud model aggregations. An enhanced design, HiFlash, incorporates adaptive staleness control and a heterogeneity-aware client-edge association strategy through deep reinforcement learning, demonstrating improved system efficiency, communication reduction, and maintained model accuracy in experiments.

A survey on poisoning attacks and defense strategies in \ac{fl} from a privacy-preserving perspective, classifying and analyzing poisoning attacks and defense mechanisms, is provided in \cite{Ch2_R53}. The paper highlights the urgency of defending against poisoning attacks and suggests potential research directions for both attack and defense strategies, emphasizing the need for systematic reviews in this area.