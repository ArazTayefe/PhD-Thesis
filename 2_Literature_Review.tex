\chapter{Literature review}

Spiking neural networks (SNNs) and their learning algorithms have garnered significant attention for their potential to model complex neural dynamics and learning processes observed in biological systems. This literature review explores various facets of SNNs, focusing on their learning mechanisms, including spike-timing-dependent plasticity (STDP), and their applications in solving computational tasks that mirror biological learning behaviors.

The work of Probst et al. (2015) presents a foundational approach to implementing probabilistic inference in networks of leaky integrate-and-fire (LIF) neurons, illustrating how Bayesian networks can be transformed and computed within spiking neural systems. The study demonstrates the potential of SNNs to perform complex computational tasks, such as probabilistic reasoning, by utilizing the dynamics of spiking neurons and synaptic plasticity, thereby bridging the gap between biological neural processes and computational models \cite{Ch2_R1}.

Markowska-Kaczmar and Koldowski (2015) explored the capabilities of spiking neural networks compared to traditional multilayer perceptrons (MLPs) in controlling virtual racing cars within a computer game environment. Their findings suggest that SNNs, despite their simplified neuron model, can outperform MLPs in tasks requiring real-time adaptability and decision-making, highlighting the efficiency of spike-based processing in dynamic environments \cite{Ch2_R2}.

Ponulak and Hopfield (2013) introduced an innovative model for rapid, parallel path planning using wavefronts of spiking neural activity. This model, inspired by hippocampal functioning, demonstrates how SNNs can efficiently solve spatial navigation problems through the propagation of activity waves, offering insights into the neural basis of navigation and the potential for neuromorphic computing applications \cite{Ch2_R3}.

Vassiliades, Cleanthous, and Christodoulou (2011) investigated multiagent reinforcement learning using spiking and nonspiking agents within the Iterated Prisoner's Dilemma framework. Their study reveals that SNNs can achieve comparable, if not superior, performance to traditional neural networks in strategic decision-making tasks, emphasizing the role of temporal spike patterns in learning and adaptation \cite{Ch2_R4}.

Markram, Gerstner, and Sjöström (2011) provided a comprehensive review of the development and significance of spike-timing-dependent plasticity (STDP) as a fundamental learning rule within neural circuits. Their historical overview underscores STDP's role in synaptic modification based on the precise timing of spikes, contributing to our understanding of learning and memory formation in the brain \cite{Ch2_R5}.

Shouval, Wang, and Wittenberg (2010) proposed that STDP emerges as a consequence of more fundamental learning rules that govern synaptic plasticity. By focusing on intracellular calcium levels as mediators of synaptic change, this work challenges the primacy of STDP, suggesting that it represents a manifestation of deeper biophysical processes that regulate synaptic strength \cite{Ch2_R6}.

Nordlie, Tetzlaff, and Einevoll (2010) delved into the rate dynamics of leaky integrate-and-fire neurons with strong synapses, examining how synaptic strength influences neural firing patterns. Their findings provide insights into the mechanisms of synaptic integration and the impact of strong synaptic connections on the computational properties of neurons \cite{Ch2_R7}.

Izhikevich (2007) addressed the distal reward problem by linking STDP with dopamine signaling, offering a model that captures the essence of reward-based learning in the brain. This work highlights the intricate interplay between neuromodulation and synaptic timing in shaping learning processes, with implications for understanding addiction and motivation \cite{Ch2_R8}.

Song, Miller, and Abbott (2000) investigated competitive Hebbian learning through STDP, revealing how synaptic efficacy is modulated by the timing of pre- and postsynaptic spikes. Their model demonstrates how STDP can lead to competitive learning outcomes without global signaling, emphasizing the significance of temporal dynamics in synaptic modification \cite{Ch2_R9}.

DeWolf et al. (2016) present a spiking neural model designed for adaptive arm control. This model integrates anatomical structures and mechanisms from the motor cortex and cerebellum to control a simulated arm. Through the use of a stability framework, the model adapts to dynamic and kinematic changes, such as arm growth or movement through different media. The work demonstrates how spiking neural networks can be applied to complex motor control problems, offering insights into both biological motor control and robotics \cite{Ch2_R10}.

Pérez et al. (2018) introduce a bio-inspired SNN for nonlinear system control, specifically focusing on UAV obstacle avoidance. Utilizing a hierarchical structure and learning through Reward-Modulated Spike-Timing-Dependent Plasticity (R-STDP), their network demonstrates high efficiency in processing visual data for control tasks. The research illustrates the potential of SNNs in directly processing sensory inputs for real-time control in robotics, showcasing a significant step towards integrating neuromorphic computing with autonomous systems \cite{Ch2_R11}.

Teeter et al. (2018) developed generalized leaky integrate-and-fire (GLIF) models to classify multiple neuron types. By fitting GLIF models to electrophysiological data from a wide range of neuron types, they demonstrate the model's ability to capture the diversity of neuronal behavior. This work contributes to the understanding of how simple neuron models can be used to represent complex neural dynamics, facilitating the study of neural circuits and their computational properties \cite{Ch2_R12}.

Mozafari et al. (2018) explored first-spike-based visual categorization using reward-modulated STDP in SNNs. Their work highlights the efficiency of SNNs in performing visual categorization tasks by exploiting the temporal dynamics of spikes. The study shows that SNNs can achieve high performance in pattern recognition tasks while maintaining low computational costs, making them suitable for neuromorphic hardware implementations \cite{Ch2_R13}.

Guo et al. (2017) investigated hierarchical Bayesian inference in SNNs, introducing a learning algorithm based on synaptic plasticity for pattern recognition. Their model demonstrates the potential of SNNs to perform complex computational tasks, such as pattern recognition, through the interplay of hierarchical structure and plasticity. This study underscores the adaptability and efficiency of SNNs in solving computational problems that require hierarchical processing \cite{Ch2_R14}.

Koul and Horiuchi (2019) focused on waypoint path planning using synaptic-dependent spike latency in SNNs for UAV control. By simulating the spiking activity of neurons in response to environmental inputs, their model efficiently generates path planning for UAVs. This work exemplifies the application of SNNs in navigation and control tasks, highlighting their potential in real-time decision-making and control in autonomous systems \cite{Ch2_R15}.

Tavanaei and Maida (2019) proposed BP-STDP, an algorithm that approximates backpropagation using spike timing dependent plasticity in SNNs. This method bridges the gap between the biologically inspired mechanisms of SNNs and the efficiency of traditional artificial neural networks. Their work contributes to the development of learning algorithms for SNNs, making them more accessible and applicable in machine learning tasks \cite{Ch2_R16}.

Bing et al. (2020) studied indirect and direct training methods for SNNs in the context of end-to-end control of a lane-keeping vehicle. Their research demonstrates the effectiveness of both training approaches in utilizing SNNs for real-world control tasks, such as autonomous driving. This study advances the understanding of how SNNs can be trained and applied in complex control systems \cite{Ch2_R17}.

Hur et al. (2020) introduced N3-CPL, a neuroplasticity-based learning method for neuromorphic networks, emphasizing cell proliferation in SNNs. This approach simulates the growth and adaptation mechanisms of biological neural networks, enhancing the learning capabilities of SNNs. The work presents a novel direction in neuromorphic computing, focusing on the dynamic adaptation and growth of neural networks \cite{Ch2_R18}.

Salt et al. (2019) investigated parameter optimization in an SNN model for UAV obstacle avoidance, targeting neuromorphic processors. By employing various optimization techniques, their work addresses the challenge of tuning SNN parameters for specific tasks. This research highlights the importance of optimization in the effective application of SNNs, especially in tasks requiring real-time processing and decision-making \cite{Ch2_R19}.

Liu et al. (2021) introduced a methodology for multi-task autonomous learning in mobile robots using SNNs. Their approach leveraged modified Integrate-and-Fire and Leaky Integrate-and-Fire neuron models, employing a task switch mechanism inspired by lateral inhibition and a novel learning algorithm based on reward-modulated Spike-Timing-Dependent Plasticity (STDP). The system demonstrated efficient autonomous learning and adaptation in tasks like obstacle avoidance and target tracking, highlighting the potential of SNNs in robotic control systems \cite{Ch2_R20}.
    
Lu et al. (2021) presented a framework that combines SNNs with binary Convolutional Neural Networks (CNNs) for reinforcement learning from images and sparse rewards. Their architecture utilizes a pre-trained binary CNN for feature extraction, enhancing the learning efficiency of SNNs in high-dimensional input scenarios. This hybrid model showcases the complementarity of SNNs and CNNs, offering promising directions for efficient and robust learning in visual environments \cite{Ch2_R21}.
    
 Zhan et al. (2021) proposed an effective transfer learning framework for SNNs, addressing the challenge of training deep SNNs with limited labeled data. By employing Centered Kernel Alignment for domain distance measurement and optimizing a domain-invariant representation, their work demonstrates the transferability and scalability of SNNs in learning tasks, suggesting a substantial step forward in the development of adaptive and intelligent neural network models \cite{Ch2_R22}.
    
Skatchkovsky, Jang, and Simeone (2021) explored neuromorphic communications, integrating SNNs with wireless communication systems. Their approach aimed at enhancing the energy efficiency and processing capabilities of battery-powered devices in bandwidth-constrained environments. By employing federated learning and neuromorphic sensing, the study opens new avenues for low-power edge intelligence and efficient communication systems \cite{Ch2_R23}.
    
Chu and Le Nguyen (2021) investigated the constraints on weights learned by Hebbian learning and STDP in spiking neurons, offering a mathematical analysis of the relationships between weight promotion/demotion probabilities and normalized weights. Their findings provide practical methods for optimizing SNN training, potentially advancing unsupervised learning mechanisms in neuromorphic computing systems \cite{Ch2_R24}.
    
Schmidgall et al. (2021) introduced "Spikepropamine," a framework that incorporates differentiable plasticity and neuromodulated synaptic plasticity within SNNs. This approach enables the networks to adaptively learn from environmental interactions, demonstrating significant improvements in task performance and adaptability, paving the way for future advancements in neuromorphic computing and robotics \cite{Ch2_R25}.
    
Golosio et al. (2021) developed NeuronGPU, a GPU-accelerated library for simulating large-scale networks of spiking neurons. Their work highlights the performance and scalability of NeuronGPU in handling complex neuronal dynamics, contributing to the computational neuroscience field by enabling more efficient simulations of SNNs \cite{Ch2_R26}.
    
Shen et al. (2021) proposed HybridSNN, a deep adaptive SNN architecture that combines the strengths of shallow SNNs with machine learning techniques. Through data-driven greedy optimization and a topological tree structure, HybridSNN achieves high performance and energy efficiency in pattern recognition tasks, demonstrating the versatility and potential of SNNs in artificial intelligence applications \cite{Ch2_R27}.
    
Chevtchenko and Ludermir (2021) explored the combination of STDP learning and binary networks in reinforcement learning tasks involving images and sparse rewards. Their methodology leverages the unique processing capabilities of SNNs for efficient learning from high-dimensional visual inputs, offering a novel approach to reinforcement learning with potential applications in visual perception systems \cite{Ch2_R28}.


Gupta et al. (2021) introduced QC_SANE, a robust control framework in DRL utilizing quantile critic with spiking actor and normalized ensemble. Their approach significantly enhances the performance and robustness of DRL systems, particularly in continuous control problems, demonstrating the potential of combining SNNs with advanced learning algorithms for efficient and robust artificial intelligence systems \cite{Ch2_R29}.